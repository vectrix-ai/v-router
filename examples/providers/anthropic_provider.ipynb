{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic Provider Guide ðŸ¤–\n",
    "\n",
    "This notebook demonstrates how to use Anthropic's Claude models through different hosting options:\n",
    "- **Direct Anthropic**: Using Anthropic's native API\n",
    "- **Vertex AI**: Using Claude through Google Cloud's Vertex AI platform\n",
    "\n",
    "## Overview\n",
    "\n",
    "Anthropic offers Claude models through multiple hosting options, each with their own advantages:\n",
    "\n",
    "### Direct Anthropic Hosting\n",
    "- **Direct API access** to Anthropic's servers\n",
    "- **Latest models** available first\n",
    "- **Simple authentication** with API key\n",
    "- **Global availability** with multiple regions\n",
    "\n",
    "### Vertex AI Hosting\n",
    "- **Enterprise features** through Google Cloud\n",
    "- **VPC integration** for secure deployments\n",
    "- **Regional compliance** options\n",
    "- **Unified billing** with other Google Cloud services\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's load environment variables for authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import base64\n",
    "import httpx\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Anthropic Hosting\n",
    "\n",
    "### Authentication\n",
    "The Anthropic client automatically uses the `ANTHROPIC_API_KEY` environment variable for authentication.\n",
    "\n",
    "### Available Models\n",
    "- `claude-sonnet-4-20250514` - Latest Sonnet model\n",
    "- `claude-opus-4-20250514` - Most capable model for complex tasks\n",
    "- `claude-haiku-4-20250115` - Fastest model for simple tasks\n",
    "\n",
    "### Resources\n",
    "- [Python SDK Documentation](https://github.com/anthropics/anthropic-sdk-python)\n",
    "- [API Reference](https://docs.anthropic.com/en/api/messages)\n",
    "- [Model Comparison](https://docs.anthropic.com/en/docs/about-claude/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Message Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Direct Anthropic Response ===\n",
      "Model: claude-sonnet-4-20250514\n",
      "Content: I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. I enjoy having conversations on a wide range of topics and helping with tasks like analysis, writing, math, coding, and creative projects.\n",
      "Usage: 28 input + 52 output = 80 total tokens\n",
      "\n",
      "=== Full Response Structure ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_016zRCc8yCHkckkHcdFsy7vA',\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. I enjoy having conversations on a wide range of topics and helping with tasks like analysis, writing, math, coding, and creative projects.\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 28,\n",
       "  'output_tokens': 52,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "# Initialize client (uses ANTHROPIC_API_KEY from environment)\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "# Basic message creation\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    system=\"You are a helpful AI assistant.\",  # System message as top-level parameter\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, Claude! Tell me about yourself in 2 sentences.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== Direct Anthropic Response ===\")\n",
    "print(f\"Model: {message.model}\")\n",
    "print(f\"Content: {message.content[0].text}\")\n",
    "print(f\"Usage: {message.usage.input_tokens} input + {message.usage.output_tokens} output = {message.usage.input_tokens + message.usage.output_tokens} total tokens\")\n",
    "\n",
    "# Full response structure\n",
    "print(\"\\n=== Full Response Structure ===\")\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Configuration\n",
    "\n",
    "Claude supports various parameters for fine-tuning responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creative Writing Response ===\n",
      "Opening line: The day gravity learned to lie, Sarah watched her coffee cup float upward while her feet remained stubbornly planted on the kitchen floor.\n",
      "Stop reason: end_turn\n"
     ]
    }
   ],
   "source": [
    "# Advanced configuration example\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,  # More creative responses\n",
    "    top_p=0.9,        # Nucleus sampling\n",
    "    system=\"You are a helpful AI assistant specializing in creative writing.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Write a creative opening line for a science fiction story.\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"=== Creative Writing Response ===\")\n",
    "print(f\"Opening line: {response.content[0].text}\")\n",
    "print(f\"Stop reason: {response.stop_reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling (Tool Use)\n",
    "\n",
    "Claude supports function calling for interacting with external tools and APIs. Here's how to implement single and multiple tool calls:\n",
    "\n",
    "### Key Features:\n",
    "- **Multiple tool calls**: Claude can call multiple tools in a single response\n",
    "- **Structured inputs**: Tools use JSON schemas for parameter validation\n",
    "- **Conversation flow**: Tool results can be fed back for continued interaction\n",
    "\n",
    "### Force tool use:\n",
    "\n",
    "- **auto** allows Claude to decide whether to call any provided tools or not. This is the default value when tools are provided.\n",
    "- **any** tells Claude that it must use one of the provided tools, but doesnâ€™t force a particular tool.\n",
    "- **tool** allows us to force Claude to always use a particular tool.\n",
    "- **none** prevents Claude from using any tools. This is the default value when no tools are provided.\n",
    "\n",
    "\n",
    "```tool_choice = {\"type\": \"tool\", \"name\": \"get_weather\"}```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Tool Call Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tool Call Response ===\n",
      "Content blocks: 1\n",
      "Block 0: tool_use\n",
      "  Tool: get_weather\n",
      "  ID: toolu_01QSAR8KnoDYHqnWpzvUqwjh\n",
      "  Input: {'location': 'San Francisco, CA'}\n",
      "\n",
      "Messages so far: 2\n"
     ]
    }
   ],
   "source": [
    "# Define a weather tool\n",
    "weather_tool = {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get the current weather in a given location\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "            },\n",
    "            \"units\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                \"description\": \"Temperature units\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Initial request with tool\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}]\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-opus-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    tools=[weather_tool],\n",
    "    messages=messages,\n",
    "    tool_choice={\"type\": \"tool\", \"name\": \"get_weather\"} # Force Claude to use the weather tool\n",
    ")\n",
    "\n",
    "print(\"=== Tool Call Response ===\")\n",
    "print(f\"Content blocks: {len(response.content)}\")\n",
    "for i, content in enumerate(response.content):\n",
    "    print(f\"Block {i}: {content.type}\")\n",
    "    if content.type == \"text\":\n",
    "        print(f\"  Text: {content.text}\")\n",
    "    elif content.type == \"tool_use\":\n",
    "        print(f\"  Tool: {content.name}\")\n",
    "        print(f\"  ID: {content.id}\")\n",
    "        print(f\"  Input: {content.input}\")\n",
    "\n",
    "# Add assistant's response to conversation\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response.content\n",
    "})\n",
    "\n",
    "print(f\"\\nMessages so far: {len(messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Execution and Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tool Execution ===\n",
      "Tool: get_weather\n",
      "Location: San Francisco, CA\n",
      "Result: 65Â°F, partly cloudy with light fog\n",
      "\n",
      "=== Final Response ===\n",
      "Claude's response: The weather in San Francisco is currently 65Â°F with partly cloudy skies and light fog. This is pretty typical weather for San Francisco! Would you like me to get the weather in Celsius instead, or for any other location?\n"
     ]
    }
   ],
   "source": [
    "# Simulate tool execution\n",
    "def execute_weather_tool(location, units=\"fahrenheit\"):\n",
    "    \"\"\"Simulate getting weather data\"\"\"\n",
    "    if \"san francisco\" in location.lower():\n",
    "        if units == \"celsius\":\n",
    "            return \"18Â°C, partly cloudy with light fog\"\n",
    "        else:\n",
    "            return \"65Â°F, partly cloudy with light fog\"\n",
    "    else:\n",
    "        return f\"Weather data not available for {location}\"\n",
    "\n",
    "# Find tool use in the response\n",
    "tool_use = None\n",
    "for content in response.content:\n",
    "    if content.type == \"tool_use\":\n",
    "        tool_use = content\n",
    "        break\n",
    "\n",
    "if tool_use:\n",
    "    # Execute the tool\n",
    "    location = tool_use.input.get(\"location\")\n",
    "    units = tool_use.input.get(\"units\", \"fahrenheit\")\n",
    "    weather_result = execute_weather_tool(location, units)\n",
    "    \n",
    "    print(f\"=== Tool Execution ===\")\n",
    "    print(f\"Tool: {tool_use.name}\")\n",
    "    print(f\"Location: {location}\")\n",
    "    print(f\"Result: {weather_result}\")\n",
    "    \n",
    "    # Send tool result back to Claude\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_use_id\": tool_use.id,\n",
    "                \"content\": weather_result\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Get final response\n",
    "    final_response = client.messages.create(\n",
    "        model=\"claude-opus-4-20250514\",\n",
    "        max_tokens=1024,\n",
    "        tools=[weather_tool],\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== Final Response ===\")\n",
    "    print(f\"Claude's response: {final_response.content[0].text}\")\n",
    "else:\n",
    "    print(\"No tool use found in response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Tools Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multiple Tools Response ===\n",
      "Total content blocks: 3\n",
      "\n",
      "Block 1: text\n",
      "  Text: I'll help you with both of those requests!\n",
      "\n",
      "Block 2: tool_use\n",
      "  Tool: calculator\n",
      "  ID: toolu_01Uru4YsD2bTTK1N1Luaw6c6\n",
      "  Input: {'operation': 'multiply', 'a': 15, 'b': 23}\n",
      "\n",
      "Block 3: tool_use\n",
      "  Tool: web_search\n",
      "  ID: toolu_0114C3kZQRYvoSC5R9CA326Q\n",
      "  Input: {'query': 'anthropic claude models'}\n",
      "\n",
      "Usage: 646 + 135 = 781 tokens\n"
     ]
    }
   ],
   "source": [
    "# Define multiple tools\n",
    "calculator_tool = {\n",
    "    \"name\": \"calculator\",\n",
    "    \"description\": \"Perform basic mathematical operations\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"operation\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"],\n",
    "                \"description\": \"The mathematical operation to perform\"\n",
    "            },\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"}\n",
    "        },\n",
    "        \"required\": [\"operation\", \"a\", \"b\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "search_tool = {\n",
    "    \"name\": \"web_search\",\n",
    "    \"description\": \"Search the web for information\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query\"\n",
    "            },\n",
    "            \"max_results\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Maximum number of results\",\n",
    "                \"default\": 5\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Request that might use multiple tools\n",
    "multi_tool_response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    tools=[weather_tool, calculator_tool, search_tool],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What's 15 * 23? Also, search for information about 'anthropic claude models'\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== Multiple Tools Response ===\")\n",
    "print(f\"Total content blocks: {len(multi_tool_response.content)}\")\n",
    "\n",
    "for i, content in enumerate(multi_tool_response.content):\n",
    "    print(f\"\\nBlock {i+1}: {content.type}\")\n",
    "    if content.type == \"text\":\n",
    "        print(f\"  Text: {content.text}\")\n",
    "    elif content.type == \"tool_use\":\n",
    "        print(f\"  Tool: {content.name}\")\n",
    "        print(f\"  ID: {content.id}\")\n",
    "        print(f\"  Input: {content.input}\")\n",
    "\n",
    "print(f\"\\nUsage: {multi_tool_response.usage.input_tokens} + {multi_tool_response.usage.output_tokens} = {multi_tool_response.usage.input_tokens + multi_tool_response.usage.output_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images and PDF-files\n",
    "\n",
    "### Images\n",
    "\n",
    "First let's try sending an image using a base64 encoded string (local file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01PwytgcunmEeUJJr8nx6ViR',\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"This is a striking macro photograph of an ant captured in what appears to be a defensive or alert posture. The ant is rearing up on its hind legs with its front legs and antennae raised, creating a dramatic silhouette. The insect has a dark, segmented body with a distinctive narrow waist typical of ants, and long, thin antennae that are clearly visible.\\n\\nThe photograph shows excellent detail, highlighting the ant's segmented abdomen, thorax, and head, as well as its six jointed legs. The ant appears to be standing on a textured surface, possibly wood or concrete, with a beautifully blurred background in warm, earthy tones of brown and orange that creates a nice depth of field effect.\\n\\nThe lighting and composition give this image an almost artistic quality, transforming what might be considered a common garden insect into an impressive subject that showcases the intricate details and interesting behaviors of these small creatures.\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 1552,\n",
       "  'output_tokens': 205,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For base64-encoded images\n",
    "image1_url = \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\"\n",
    "image1_media_type = \"image/jpeg\"\n",
    "image1_data = base64.standard_b64encode(httpx.get(image1_url).content).decode(\"utf-8\")\n",
    "# For URL-based images, you can use the URLs directly in your requests\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": image1_media_type,\n",
    "                        \"data\": image1_data,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe this image.\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also just pass a URL if it's a public image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01DRLmgT72TDXiuKQfgzYGiQ',\n",
       " 'content': [{'citations': None,\n",
       "   'text': 'This is a close-up photograph of an ant captured in a defensive or alert posture. The ant appears to be rearing up on its hind legs with its front legs and antennae raised, creating a striking silhouette against the blurred background. The ant has a dark, glossy exoskeleton with distinctive segmentation visible in its head, thorax, and abdomen. Its long, thin antennae are clearly visible, as are its slender legs. The photograph is taken at ground level on what appears to be a concrete or stone surface, with a shallow depth of field that creates an artistic bokeh effect in the warm-toned background. The lighting and composition give this common insect a dramatic, almost sculptural quality, highlighting the intricate details of its anatomy and posture.',\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 1552,\n",
       "  'output_tokens': 171,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"url\",\n",
    "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe this image.\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF-Files\n",
    "Use a base64 encoded PDF-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01UMvgcHtBPQEMN1Hz6eUTb6',\n",
       " 'content': [{'citations': None,\n",
       "   'text': 'Based on the Model Card Addendum, here are the key findings:\\n\\n## **New Models Released:**\\n1. **Upgraded Claude 3.5 Sonnet** - An improved version of the existing model\\n2. **Claude 3.5 Haiku** - A new, smaller model in the Claude 3 family\\n\\n## **Major New Capability:**\\n- **Computer Use**: The upgraded Claude 3.5 Sonnet can interpret screenshots and generate GUI commands to perform tasks, enabling it to:\\n  - Navigate websites and applications\\n  - Interact with user interfaces (clicking, typing, moving cursor)\\n  - Complete complex multi-step processes\\n\\n## **Performance Achievements:**\\n\\n### **State-of-the-Art Results:**\\n- **SWE-bench Verified**: 49.0% (software engineering tasks)\\n- **TAU-bench**: 69.2% retail, 46.0% airline (customer service tasks)\\n- **OSWorld**: 14.9% success rate (computer use tasks)\\n- Multiple vision benchmarks including MathVista, AI2D, and ChartQA\\n\\n### **Claude 3.5 Haiku Performance:**\\n- Performs comparably to original Claude 3.5 Sonnet and Claude 3 Opus\\n- 40.6% on SWE-bench Verified\\n- Strong performance in reasoning and instruction following\\n\\n## **Knowledge Cutoffs:**\\n- Upgraded Claude 3.5 Sonnet: April 2024\\n- Claude 3.5 Haiku: July 2024\\n\\n## **Safety Findings:**\\n- Both models classified as ASL-2 (AI Safety Level 2)\\n- Extensive safety evaluations conducted with US AISI, UK AISI, and METR\\n- No indicators of catastrophic risk found\\n- Improved resistance to prompt injection\\n- Better performance on refusal benchmarks\\n\\n## **Human Evaluation Results:**\\nThe upgraded Claude 3.5 Sonnet shows improvements over the original in:\\n- Document analysis (61% win rate)\\n- Visual understanding (57%)\\n- Creative writing (58%)\\n- Coding (52%)\\n- Instruction following (51%)',\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-opus-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 32501,\n",
       "  'output_tokens': 497,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, load and encode the PDF \n",
    "pdf_url = \"https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf\"\n",
    "pdf_data = base64.standard_b64encode(httpx.get(pdf_url).content).decode(\"utf-8\")\n",
    "\n",
    "# Alternative: Load from a local file\n",
    "# with open(\"document.pdf\", \"rb\") as f:\n",
    "#     pdf_data = base64.standard_b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# Send to Claude using base64 encoding\n",
    "client = anthropic.Anthropic()\n",
    "message = client.messages.create(\n",
    "    model=\"claude-opus-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"application/pdf\",\n",
    "                        \"data\": pdf_data\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What are the key findings in this document?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload a file using the Files API.\n",
    "\n",
    "This can come in handy when you want to pass the same file multiple times, for example in a conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'file_011CPxKhM8UxwqUb4hywiGSZ',\n",
       " 'created_at': datetime.datetime(2025, 6, 9, 8, 21, 53, 964000, tzinfo=datetime.timezone.utc),\n",
       " 'filename': 'document.pdf',\n",
       " 'mime_type': 'application/pdf',\n",
       " 'size_bytes': 1042289,\n",
       " 'type': 'file',\n",
       " 'downloadable': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = anthropic.Anthropic()\n",
    "file = client.beta.files.upload(\n",
    "  file=(\"document.pdf\", open(\"./assets/gameboy_color.pdf\", \"rb\"), \"application/pdf\"),\n",
    ")\n",
    "\n",
    "file.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BetaMessage(id='msg_01BHFkCyff5NyL1PjoDPNvJh', container=None, content=[BetaTextBlock(citations=None, text=\"This is an instruction manual for the Nintendo Game Boy Color handheld video game system. Here's a summary of the key sections:\\n\\n## Main Content:\\n\\n**Setup & Components:**\\n- Lists all included components (Game Boy Color unit, wrist strap, batteries, etc.)\\n- Describes each part including infrared communication port, power switch, volume control, and color LCD screen\\n\\n**Power & Battery Installation:**\\n- Instructions for installing 2 AA batteries\\n- Cautions about proper battery insertion and replacement\\n- Battery safety warnings\\n\\n**Game Compatibility:**\\n- Three types of Game Paks work with the system:\\n  - Original Game Boy games (monochrome)\\n  - Dual-mode games (enhanced colors on Game Boy Color)\\n  - Game Boy Color exclusive games (full color)\\n\\n**Basic Operation:**\\n- How to insert/remove Game Paks\\n- Power on/off procedures\\n- Screen color adjustment options for original Game Boy games\\n\\n**Multiplayer Features:**\\n- Two-player gameplay using Game Link Cable\\n- Infrared communication port for wireless connection between nearby units\\n\\n**Technical Information:**\\n- Troubleshooting guide for common issues\\n- Warranty and service information\\n- Parts list with order numbers and prices\\n- Contact information for Nintendo customer service\\n\\n**Safety Warnings:**\\n- Cautions about battery usage, including warnings not to use rechargeable battery packs\\n- Proper handling and care instructions\\n\\nThe manual emphasizes compatibility with the existing Game Boy game library while highlighting the new color display capabilities.\", type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=BetaUsage(cache_creation=None, cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=3170, output_tokens=336, server_tool_use=None, service_tier='standard'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01BHFkCyff5NyL1PjoDPNvJh',\n",
       " 'container': None,\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"This is an instruction manual for the Nintendo Game Boy Color handheld video game system. Here's a summary of the key sections:\\n\\n## Main Content:\\n\\n**Setup & Components:**\\n- Lists all included components (Game Boy Color unit, wrist strap, batteries, etc.)\\n- Describes each part including infrared communication port, power switch, volume control, and color LCD screen\\n\\n**Power & Battery Installation:**\\n- Instructions for installing 2 AA batteries\\n- Cautions about proper battery insertion and replacement\\n- Battery safety warnings\\n\\n**Game Compatibility:**\\n- Three types of Game Paks work with the system:\\n  - Original Game Boy games (monochrome)\\n  - Dual-mode games (enhanced colors on Game Boy Color)\\n  - Game Boy Color exclusive games (full color)\\n\\n**Basic Operation:**\\n- How to insert/remove Game Paks\\n- Power on/off procedures\\n- Screen color adjustment options for original Game Boy games\\n\\n**Multiplayer Features:**\\n- Two-player gameplay using Game Link Cable\\n- Infrared communication port for wireless connection between nearby units\\n\\n**Technical Information:**\\n- Troubleshooting guide for common issues\\n- Warranty and service information\\n- Parts list with order numbers and prices\\n- Contact information for Nintendo customer service\\n\\n**Safety Warnings:**\\n- Cautions about battery usage, including warnings not to use rechargeable battery packs\\n- Proper handling and care instructions\\n\\nThe manual emphasizes compatibility with the existing Game Boy game library while highlighting the new color display capabilities.\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation': None,\n",
       "  'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 3170,\n",
       "  'output_tokens': 336,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.beta.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Please summarize this document for me.\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"file\",\n",
    "                        \"file_id\": file.id\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    betas=[\"files-api-2025-04-14\"],\n",
    ")\n",
    "print(response)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex AI Hosting\n",
    "\n",
    "### Setup and Authentication\n",
    "Vertex AI requires Google Cloud project configuration and regional settings.\n",
    "\n",
    "### Key Differences:\n",
    "- **Project ID**: Must specify your Google Cloud project\n",
    "- **Region**: Choose deployment region for compliance/latency\n",
    "- **Model Names**: Slightly different naming convention with `@` version suffix\n",
    "- **Enterprise Features**: VPC integration, audit logging, and enterprise security\n",
    "\n",
    "### Available Regions:\n",
    "- `us-central1` - United States (primary)\n",
    "- `us-east4` - United States (secondary)\n",
    "- `europe-west1` - Europe (primary)\n",
    "- See [Vertex AI Locations](https://cloud.google.com/vertex-ai/docs/general/locations) for complete list\n",
    "\n",
    "### Resources:\n",
    "- [Anthropic on Vertex AI Documentation](https://docs.anthropic.com/en/api/claude-on-vertex-ai)\n",
    "- [Google Cloud Vertex AI](https://cloud.google.com/vertex-ai)\n",
    "- [Model Garden](https://console.cloud.google.com/vertex-ai/model-garden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Vertex AI Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Vertex AI:\n",
      "  Project: vectrix-401014\n",
      "  Region: europe-west1\n",
      "\n",
      "=== Vertex AI Response ===\n",
      "Model: claude-sonnet-4-20250514\n",
      "Content: Here's a breakdown of the key differences between using Claude on Vertex AI versus Anthropic's direct hosting:\n",
      "\n",
      "## **Vertex AI (Google Cloud)**\n",
      "\n",
      "**Advantages:**\n",
      "- **Integrated ecosystem**: Seamlessly works with other Google Cloud services (BigQuery, Cloud Storage, etc.)\n",
      "- **Enterprise tooling**: Built-in monitoring, logging, and MLOps capabilities\n",
      "- **Unified billing**: Single invoice for all Google Cloud services\n",
      "- **Security\n",
      "Usage: 24 + 100 = 124 tokens\n",
      "\n",
      "=== Full Response Structure ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_vrtx_01PthiLp53yGALdw1nQUy8z5',\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"Here's a breakdown of the key differences between using Claude on Vertex AI versus Anthropic's direct hosting:\\n\\n## **Vertex AI (Google Cloud)**\\n\\n**Advantages:**\\n- **Integrated ecosystem**: Seamlessly works with other Google Cloud services (BigQuery, Cloud Storage, etc.)\\n- **Enterprise tooling**: Built-in monitoring, logging, and MLOps capabilities\\n- **Unified billing**: Single invoice for all Google Cloud services\\n- **Security\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'max_tokens',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 24,\n",
       "  'output_tokens': 100,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': None}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anthropic import AnthropicVertex\n",
    "\n",
    "# Initialize Vertex AI client\n",
    "project_id = os.getenv(\"GCP_PROJECT_ID\")\n",
    "region = os.getenv(\"GCP_LOCATION\", \"us-central1\")  # Default to us-central1\n",
    "\n",
    "print(f\"Connecting to Vertex AI:\")\n",
    "print(f\"  Project: {project_id}\")\n",
    "print(f\"  Region: {region}\")\n",
    "\n",
    "vertex_client = AnthropicVertex(project_id=project_id, region=region)\n",
    "\n",
    "# Note: Vertex AI uses @ notation for model versions\n",
    "vertex_response = vertex_client.messages.create(\n",
    "    model=\"claude-sonnet-4@20250514\",\n",
    "    max_tokens=100,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello! Explain the difference between Vertex AI and direct Anthropic hosting.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"\\n=== Vertex AI Response ===\")\n",
    "print(f\"Model: {vertex_response.model}\")\n",
    "print(f\"Content: {vertex_response.content[0].text}\")\n",
    "print(f\"Usage: {vertex_response.usage.input_tokens} + {vertex_response.usage.output_tokens} = {vertex_response.usage.input_tokens + vertex_response.usage.output_tokens} tokens\")\n",
    "\n",
    "# Full response structure (same as direct Anthropic)\n",
    "print(\"\\n=== Full Response Structure ===\")\n",
    "vertex_response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertex AI Function Calling\n",
    "\n",
    "Function calling works identically on Vertex AI as with direct Anthropic hosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vertex AI Tool Call ===\n",
      "Model: claude-sonnet-4-20250514\n",
      "Tool: calculator\n",
      "Operation: divide\n",
      "Numbers: 42 divide 7\n",
      "\n",
      "âœ… Tool calling works identically on Vertex AI!\n"
     ]
    }
   ],
   "source": [
    "# Function calling works the same on Vertex AI\n",
    "vertex_tool_response = vertex_client.messages.create(\n",
    "    model=\"claude-sonnet-4@20250514\",\n",
    "    max_tokens=1024,\n",
    "    tools=[calculator_tool],  # Same tool definition as before\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Calculate 42 divided by 7\"}\n",
    "    ],\n",
    "    tool_choice={\"type\": \"tool\", \"name\": \"calculator\"}  # Must match the tool name\n",
    ")\n",
    "\n",
    "print(\"=== Vertex AI Tool Call ===\")\n",
    "print(f\"Model: {vertex_tool_response.model}\")\n",
    "\n",
    "for content in vertex_tool_response.content:\n",
    "    if content.type == \"text\":\n",
    "        print(f\"Text: {content.text}\")\n",
    "    elif content.type == \"tool_use\":\n",
    "        print(f\"Tool: {content.name}\")\n",
    "        print(f\"Operation: {content.input['operation']}\")\n",
    "        print(f\"Numbers: {content.input['a']} {content.input['operation']} {content.input['b']}\")\n",
    "\n",
    "print(f\"\\nâœ… Tool calling works identically on Vertex AI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01CHmobiAyXk5KQRTFGnG3G2',\n",
       " 'content': [{'signature': 'EtwCCkYIBBgCKkAWGW+Pr35f4lBAMsracpGyyHnE6meE60N4qMfhrSKpygd1a7dREeihegj6sqWViwjUAkAsSB5bKo0dKr9cuAZLEgxbLgwLI4HQc1iBsnIaDBFZLruNeO38AM3sXyIwVgvUCAd/hhgBSGeNig0rztLUBGiNKixaUgsMffeRljUaT2gEPa3ppvw5Qt/G08o4KsMB3UQIb6B4HMufAGtG8lleal9KlUOpkAXkg5+GJ/9iSYh0VoSRAQjr3BgStYZiJtAvxFfSISZlflXqnml27oYobqNr2iTeSiZWDXEO5nBdvkgXZrDluVSflT4mG9QMIcVbrHuuaP5jHO0DPc8RoOcDQ7D3tacKet9ouKRAuR3vlqgdD0fYD6zmm3eemmXkKjXqzG6VoM9Fk/z+SWZxK1tytCTsE8DZvd6koHtkJSKLo58m+cpvF2udjZCwIRf1Is4ctJH8GAE=',\n",
       "   'thinking': 'The user is asking for a simple Python function that prints \"Hello, World!\". This is a very basic programming task. I should write a clean, simple function that accomplishes this.',\n",
       "   'type': 'thinking'},\n",
       "  {'citations': None,\n",
       "   'text': 'Here\\'s a simple Python function that prints \"Hello, World!\":\\n\\n```python\\ndef hello_world():\\n    print(\"Hello, World!\")\\n\\n# Call the function\\nhello_world()\\n```\\n\\nYou can also make it more flexible by adding a parameter:\\n\\n```python\\ndef greet(message=\"Hello, World!\"):\\n    print(message)\\n\\n# Call with default message\\ngreet()\\n\\n# Call with custom message\\ngreet(\"Hello, Python!\")\\n```\\n\\nThe first version is the simplest implementation that directly prints \"Hello, World!\" when called. The second version allows you to optionally pass a custom message while still defaulting to \"Hello, World!\" if no argument is provided.',\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-opus-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 48,\n",
       "  'output_tokens': 201,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.messages.create(\n",
    "    model=\"claude-opus-4-20250514\",\n",
    "    max_tokens=32000,\n",
    "    temperature=1,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Write a short Python function that prints 'Hello, World!'\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    thinking={\n",
    "        \"type\": \"enabled\",\n",
    "        \"budget_tokens\": 10000\n",
    "    },\n",
    "    timeout=600, # Always add a timeout parameter when enabling thinking\n",
    ")\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Direct vs Vertex AI\n",
    "\n",
    "Let's compare the same request across both hosting options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Comparison: Direct vs Vertex AI ===\n",
      "\n",
      "ðŸ”µ Direct Anthropic:\n",
      "Model: claude-sonnet-4-20250514\n",
      "Response: Quantum computing harnesses quantum mechanics principles like superposition and entanglement to process information. Unlike classical bits (0 or 1), quantum bits (qubits) exist in multiple states simultaneously, enabling parallel computations. This allows quantum computers to potentially solve certain complex problems exponentially faster than classical computers, revolutionizing cryptography, optimization, and scientific simulation.\n",
      "Tokens: 18 + 79\n",
      "\n",
      "ðŸŸ¢ Vertex AI:\n",
      "Model: claude-sonnet-4-20250514\n",
      "Response: Quantum computing harnesses quantum mechanics principles like superposition and entanglement to process information. Unlike classical bits (0 or 1), quantum bits (qubits) exist in multiple states simultaneously, enabling parallel calculations. This allows quantum computers to solve certain complex problems exponentially faster than classical computers, particularly in cryptography, optimization, and simulation.\n",
      "Tokens: 18 + 75\n",
      "\n",
      "ðŸ’¡ Both use identical APIs and response formats!\n",
      "ðŸ’¡ Only differences: authentication method and model naming convention\n"
     ]
    }
   ],
   "source": [
    "test_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Explain quantum computing in exactly 50 words.\"}\n",
    "]\n",
    "\n",
    "print(\"=== Comparison: Direct vs Vertex AI ===\")\n",
    "\n",
    "# Direct Anthropic\n",
    "direct_response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=100,\n",
    "    messages=test_messages\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ”µ Direct Anthropic:\")\n",
    "print(f\"Model: {direct_response.model}\")\n",
    "print(f\"Response: {direct_response.content[0].text}\")\n",
    "print(f\"Tokens: {direct_response.usage.input_tokens} + {direct_response.usage.output_tokens}\")\n",
    "\n",
    "# Vertex AI\n",
    "vertex_response = vertex_client.messages.create(\n",
    "    model=\"claude-sonnet-4@20250514\",\n",
    "    max_tokens=100,\n",
    "    messages=test_messages\n",
    ")\n",
    "\n",
    "print(\"\\nðŸŸ¢ Vertex AI:\")\n",
    "print(f\"Model: {vertex_response.model}\")\n",
    "print(f\"Response: {vertex_response.content[0].text}\")\n",
    "print(f\"Tokens: {vertex_response.usage.input_tokens} + {vertex_response.usage.output_tokens}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Both use identical APIs and response formats!\")\n",
    "print(\"ðŸ’¡ Only differences: authentication method and model naming convention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### When to Use Direct Anthropic:\n",
    "- **Rapid prototyping** and development\n",
    "- **Latest model access** and features\n",
    "- **Simple deployment** requirements\n",
    "- **Global applications** without specific regional needs\n",
    "\n",
    "### When to Use Vertex AI:\n",
    "- **Enterprise deployments** with strict security requirements\n",
    "- **VPC integration** for network isolation\n",
    "- **Regional compliance** needs (data residency)\n",
    "- **Unified Google Cloud billing** and management\n",
    "- **Advanced monitoring** and audit logging requirements\n",
    "\n",
    "### Error Handling:\n",
    "```python\n",
    "try:\n",
    "    response = client.messages.create(...)  # or vertex_client\n",
    "except anthropic.APIError as e:\n",
    "    print(f\"API Error: {e}\")\n",
    "except anthropic.RateLimitError as e:\n",
    "    print(f\"Rate limit exceeded: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "```\n",
    "\n",
    "### Performance Tips:\n",
    "- **Choose appropriate max_tokens** based on your use case\n",
    "- **Use streaming** for long responses: `stream=True`\n",
    "- **Implement retry logic** for production applications\n",
    "- **Monitor token usage** to optimize costs\n",
    "\n",
    "## Summary\n",
    "\n",
    "âœ… **Identical APIs**: Both hosting options use the same Anthropic Python SDK  \n",
    "âœ… **Same Features**: Function calling, streaming, and all model capabilities work identically  \n",
    "âœ… **Flexible Deployment**: Choose based on your security, compliance, and infrastructure needs  \n",
    "âœ… **Enterprise Ready**: Vertex AI provides additional enterprise features when needed  \n",
    "\n",
    "Both direct Anthropic and Vertex AI hosting provide access to the same powerful Claude models with identical APIs, giving you flexibility in how you deploy and scale your applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
