{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic Provider Guide ðŸ¤–\n",
    "\n",
    "This notebook demonstrates how to use Anthropic's Claude models through different hosting options:\n",
    "- **Direct Anthropic**: Using Anthropic's native API\n",
    "- **Vertex AI**: Using Claude through Google Cloud's Vertex AI platform\n",
    "\n",
    "## Overview\n",
    "\n",
    "Anthropic offers Claude models through multiple hosting options, each with their own advantages:\n",
    "\n",
    "### Direct Anthropic Hosting\n",
    "- **Direct API access** to Anthropic's servers\n",
    "- **Latest models** available first\n",
    "- **Simple authentication** with API key\n",
    "- **Global availability** with multiple regions\n",
    "\n",
    "### Vertex AI Hosting\n",
    "- **Enterprise features** through Google Cloud\n",
    "- **VPC integration** for secure deployments\n",
    "- **Regional compliance** options\n",
    "- **Unified billing** with other Google Cloud services\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's load environment variables for authentication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import base64\n",
    "import httpx\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Anthropic Hosting\n",
    "\n",
    "### Authentication\n",
    "The Anthropic client automatically uses the `ANTHROPIC_API_KEY` environment variable for authentication.\n",
    "\n",
    "### Available Models\n",
    "- `claude-sonnet-4-20250514` - Latest Sonnet model\n",
    "- `claude-opus-4-20250514` - Most capable model for complex tasks\n",
    "- `claude-haiku-4-20250115` - Fastest model for simple tasks\n",
    "\n",
    "### Resources\n",
    "- [Python SDK Documentation](https://github.com/anthropics/anthropic-sdk-python)\n",
    "- [API Reference](https://docs.anthropic.com/en/api/messages)\n",
    "- [Model Comparison](https://docs.anthropic.com/en/docs/about-claude/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Message Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Direct Anthropic Response ===\n",
      "Model: claude-sonnet-4-20250514\n",
      "Content: I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. I enjoy having conversations on a wide range of topics and helping with tasks like analysis, writing, math, coding, and creative projects.\n",
      "Usage: 28 input + 52 output = 80 total tokens\n",
      "\n",
      "=== Full Response Structure ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_013gSXyrbJwiXD8LNdASPQ4B',\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"I'm Claude, an AI assistant created by Anthropic to be helpful, harmless, and honest. I enjoy having conversations on a wide range of topics and helping with tasks like analysis, writing, math, coding, and creative projects.\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 28,\n",
       "  'output_tokens': 52,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "# Initialize client (uses ANTHROPIC_API_KEY from environment)\n",
    "client = anthropic.Anthropic()\n",
    "\n",
    "# Basic message creation\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    system=\"You are a helpful AI assistant.\",  # System message as top-level parameter\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, Claude! Tell me about yourself in 2 sentences.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== Direct Anthropic Response ===\")\n",
    "print(f\"Model: {message.model}\")\n",
    "print(f\"Content: {message.content[0].text}\")\n",
    "print(f\"Usage: {message.usage.input_tokens} input + {message.usage.output_tokens} output = {message.usage.input_tokens + message.usage.output_tokens} total tokens\")\n",
    "\n",
    "# Full response structure\n",
    "print(\"\\n=== Full Response Structure ===\")\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Configuration\n",
    "\n",
    "Claude supports various parameters for fine-tuning responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creative Writing Response ===\n",
      "Opening line: The last human on Earth received a text message at 3:47 AM that simply read: \"We need to talk. â€”Humanity\"\n",
      "Stop reason: end_turn\n"
     ]
    }
   ],
   "source": [
    "# Advanced configuration example\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,  # More creative responses\n",
    "    top_p=0.9,        # Nucleus sampling\n",
    "    system=\"You are a helpful AI assistant specializing in creative writing.\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"Write a creative opening line for a science fiction story.\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"=== Creative Writing Response ===\")\n",
    "print(f\"Opening line: {response.content[0].text}\")\n",
    "print(f\"Stop reason: {response.stop_reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Calling (Tool Use)\n",
    "\n",
    "Claude supports function calling for interacting with external tools and APIs. Here's how to implement single and multiple tool calls:\n",
    "\n",
    "### Key Features:\n",
    "- **Multiple tool calls**: Claude can call multiple tools in a single response\n",
    "- **Structured inputs**: Tools use JSON schemas for parameter validation\n",
    "- **Conversation flow**: Tool results can be fed back for continued interaction\n",
    "\n",
    "### Force tool use:\n",
    "\n",
    "- **auto** allows Claude to decide whether to call any provided tools or not. This is the default value when tools are provided.\n",
    "- **any** tells Claude that it must use one of the provided tools, but doesnâ€™t force a particular tool.\n",
    "- **tool** allows us to force Claude to always use a particular tool.\n",
    "- **none** prevents Claude from using any tools. This is the default value when no tools are provided.\n",
    "\n",
    "\n",
    "```tool_choice = {\"type\": \"tool\", \"name\": \"get_weather\"}```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Tool Call Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tool Call Response ===\n",
      "Content blocks: 1\n",
      "Block 0: tool_use\n",
      "  Tool: get_weather\n",
      "  ID: toolu_01Q7VwiPsrLdLPMAHR4RSCD3\n",
      "  Input: {'location': 'San Francisco, CA'}\n",
      "\n",
      "Messages so far: 2\n"
     ]
    }
   ],
   "source": [
    "# Define a weather tool\n",
    "weather_tool = {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get the current weather in a given location\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "            },\n",
    "            \"units\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                \"description\": \"Temperature units\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Initial request with tool\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}]\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-opus-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    tools=[weather_tool],\n",
    "    messages=messages,\n",
    "    tool_choice={\"type\": \"tool\", \"name\": \"get_weather\"} # Force Claude to use the weather tool\n",
    ")\n",
    "\n",
    "print(\"=== Tool Call Response ===\")\n",
    "print(f\"Content blocks: {len(response.content)}\")\n",
    "for i, content in enumerate(response.content):\n",
    "    print(f\"Block {i}: {content.type}\")\n",
    "    if content.type == \"text\":\n",
    "        print(f\"  Text: {content.text}\")\n",
    "    elif content.type == \"tool_use\":\n",
    "        print(f\"  Tool: {content.name}\")\n",
    "        print(f\"  ID: {content.id}\")\n",
    "        print(f\"  Input: {content.input}\")\n",
    "\n",
    "# Add assistant's response to conversation\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response.content\n",
    "})\n",
    "\n",
    "print(f\"\\nMessages so far: {len(messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Execution and Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tool Execution ===\n",
      "Tool: get_weather\n",
      "Location: San Francisco, CA\n",
      "Result: 65Â°F, partly cloudy with light fog\n",
      "\n",
      "=== Final Response ===\n",
      "Claude's response: The current weather in San Francisco is 65Â°F (about 18Â°C), partly cloudy with light fog. This is typical San Francisco weather - mild temperatures with some coastal fog.\n"
     ]
    }
   ],
   "source": [
    "# Simulate tool execution\n",
    "def execute_weather_tool(location, units=\"fahrenheit\"):\n",
    "    \"\"\"Simulate getting weather data\"\"\"\n",
    "    if \"san francisco\" in location.lower():\n",
    "        if units == \"celsius\":\n",
    "            return \"18Â°C, partly cloudy with light fog\"\n",
    "        else:\n",
    "            return \"65Â°F, partly cloudy with light fog\"\n",
    "    else:\n",
    "        return f\"Weather data not available for {location}\"\n",
    "\n",
    "# Find tool use in the response\n",
    "tool_use = None\n",
    "for content in response.content:\n",
    "    if content.type == \"tool_use\":\n",
    "        tool_use = content\n",
    "        break\n",
    "\n",
    "if tool_use:\n",
    "    # Execute the tool\n",
    "    location = tool_use.input.get(\"location\")\n",
    "    units = tool_use.input.get(\"units\", \"fahrenheit\")\n",
    "    weather_result = execute_weather_tool(location, units)\n",
    "    \n",
    "    print(f\"=== Tool Execution ===\")\n",
    "    print(f\"Tool: {tool_use.name}\")\n",
    "    print(f\"Location: {location}\")\n",
    "    print(f\"Result: {weather_result}\")\n",
    "    \n",
    "    # Send tool result back to Claude\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"tool_result\",\n",
    "                \"tool_use_id\": tool_use.id,\n",
    "                \"content\": weather_result\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Get final response\n",
    "    final_response = client.messages.create(\n",
    "        model=\"claude-opus-4-20250514\",\n",
    "        max_tokens=1024,\n",
    "        tools=[weather_tool],\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n=== Final Response ===\")\n",
    "    print(f\"Claude's response: {final_response.content[0].text}\")\n",
    "else:\n",
    "    print(\"No tool use found in response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Tools Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Multiple Tools Response ===\n",
      "Total content blocks: 3\n",
      "\n",
      "Block 1: text\n",
      "  Text: I'll help you with both requests - calculating 15 * 23 and searching for information about Anthropic Claude models.\n",
      "\n",
      "Block 2: tool_use\n",
      "  Tool: calculator\n",
      "  ID: toolu_014PUoqdUjmh2Vfqd4uzjX9H\n",
      "  Input: {'operation': 'multiply', 'a': 15, 'b': 23}\n",
      "\n",
      "Block 3: tool_use\n",
      "  Tool: web_search\n",
      "  ID: toolu_01EDhWuJGae4Bk67Ei2arCAg\n",
      "  Input: {'query': 'anthropic claude models'}\n",
      "\n",
      "Usage: 646 + 152 = 798 tokens\n"
     ]
    }
   ],
   "source": [
    "# Define multiple tools\n",
    "calculator_tool = {\n",
    "    \"name\": \"calculator\",\n",
    "    \"description\": \"Perform basic mathematical operations\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"operation\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"],\n",
    "                \"description\": \"The mathematical operation to perform\"\n",
    "            },\n",
    "            \"a\": {\"type\": \"number\", \"description\": \"First number\"},\n",
    "            \"b\": {\"type\": \"number\", \"description\": \"Second number\"}\n",
    "        },\n",
    "        \"required\": [\"operation\", \"a\", \"b\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "search_tool = {\n",
    "    \"name\": \"web_search\",\n",
    "    \"description\": \"Search the web for information\",\n",
    "    \"input_schema\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Search query\"\n",
    "            },\n",
    "            \"max_results\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Maximum number of results\",\n",
    "                \"default\": 5\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Request that might use multiple tools\n",
    "multi_tool_response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    tools=[weather_tool, calculator_tool, search_tool],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"What's 15 * 23? Also, search for information about 'anthropic claude models'\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"=== Multiple Tools Response ===\")\n",
    "print(f\"Total content blocks: {len(multi_tool_response.content)}\")\n",
    "\n",
    "for i, content in enumerate(multi_tool_response.content):\n",
    "    print(f\"\\nBlock {i+1}: {content.type}\")\n",
    "    if content.type == \"text\":\n",
    "        print(f\"  Text: {content.text}\")\n",
    "    elif content.type == \"tool_use\":\n",
    "        print(f\"  Tool: {content.name}\")\n",
    "        print(f\"  ID: {content.id}\")\n",
    "        print(f\"  Input: {content.input}\")\n",
    "\n",
    "print(f\"\\nUsage: {multi_tool_response.usage.input_tokens} + {multi_tool_response.usage.output_tokens} = {multi_tool_response.usage.input_tokens + multi_tool_response.usage.output_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images and PDF-files\n",
    "\n",
    "### Images\n",
    "\n",
    "First let's try sending an image using a base64 encoded string (local file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01MS9vHyo9tnnrzpFRSm2vny',\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"This is a close-up macro photograph of an ant in a defensive or alert posture. The ant appears to be rearing up on its hind legs with its front legs and antennae raised, creating a striking silhouette against the blurred background. The ant has a dark, segmented body with a distinctive narrow waist between the thorax and abdomen, and long, thin legs and antennae that are clearly visible. The image is shot with shallow depth of field, keeping the ant in sharp focus while the background is artistically blurred with warm, earthy tones. The ant is positioned on what appears to be a textured surface, possibly concrete or stone. The lighting and composition create a dramatic effect that emphasizes the ant's posture and the intricate details of its anatomy.\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 1552,\n",
       "  'output_tokens': 170,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For base64-encoded images\n",
    "image1_url = \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\"\n",
    "image1_media_type = \"image/jpeg\"\n",
    "image1_data = base64.standard_b64encode(httpx.get(image1_url).content).decode(\"utf-8\")\n",
    "# For URL-based images, you can use the URLs directly in your requests\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": image1_media_type,\n",
    "                        \"data\": image1_data,\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe this image.\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also just pass a URL if it's a public image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01YWjPS8fuAUUvQonLw15nzY',\n",
       " 'content': [{'citations': None,\n",
       "   'text': 'This is a close-up macro photograph of an ant in a defensive or alert posture. The ant appears to be rearing up on its hind legs with its front legs and antennae raised, creating a striking silhouette against the blurred background. The ant has a dark, segmented body with a distinctive narrow waist (petiole) connecting the thorax and abdomen, which is characteristic of ants. Its long, thin antennae are clearly visible, and the image captures fine details of its body structure and legs. The ant is positioned on what appears to be a concrete or stone surface, and the background is artistically blurred with warm, muted tones that help emphasize the subject. This defensive posture might be a threat display or simply the ant investigating its surroundings.',\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 1552,\n",
       "  'output_tokens': 172,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"url\",\n",
    "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\",\n",
    "                    },\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Describe this image.\"\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF-Files\n",
    "Use a base64 encoded PDF-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01Ao7XmgbueP2RggJcZFQ7tk',\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"Based on this Model Card Addendum, here are the key findings:\\n\\n## New Models Introduced:\\n1. **Upgraded Claude 3.5 Sonnet** - An improved version of the original Claude 3.5 Sonnet\\n2. **Claude 3.5 Haiku** - A new, smaller model in the Claude 3 family\\n\\n## Major New Capability - Computer Use:\\n- The upgraded Claude 3.5 Sonnet can now interpret screenshots and interact with computer interfaces\\n- Achieves 14.9% success rate on OSWorld benchmark (22% with extended steps)\\n- Can navigate websites, click buttons, type, and complete multi-step processes\\n- Still well below human performance (72.36%), indicating room for improvement\\n\\n## Performance Improvements:\\n\\n### Upgraded Claude 3.5 Sonnet:\\n- **SWE-bench Verified**: 49.0% (state-of-the-art for solving real GitHub issues)\\n- **TAU-bench**: 69.2% retail, 46.0% airline (state-of-the-art)\\n- **AIME 2024**: 16.0% (high school math competition)\\n- **MathVista**: 70.7% (visual mathematical reasoning)\\n- Outperforms original Claude 3.5 Sonnet in coding, document analysis, visual understanding, and creative writing\\n\\n### Claude 3.5 Haiku:\\n- Performs comparably to original Claude 3.5 Sonnet and Claude 3 Opus in many tasks\\n- **SWE-bench Verified**: 40.6% (better than original Claude 3.5 Sonnet's 33.4%)\\n- Strong performance despite being the smallest model\\n\\n## Knowledge Cutoffs:\\n- Upgraded Claude 3.5 Sonnet: April 2024\\n- Claude 3.5 Haiku: July 2024\\n\\n## Safety Findings:\\n- Both models classified as ASL-2 (AI Safety Level 2) - no catastrophic risks identified\\n- Comprehensive safety testing conducted with US and UK AI Safety Institutes\\n- Enhanced resistance to prompt injection attacks\\n- Some challenges with nuanced requests or fictional/artistic content\\n\\n## Key Takeaway:\\nThese models represent significant advances in AI capabilities, particularly in computer use automation, while maintaining safety standards. The computer use feature, while groundbreaking, is still in early stages of development.\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-opus-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 32501,\n",
       "  'output_tokens': 555,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, load and encode the PDF \n",
    "pdf_url = \"https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf\"\n",
    "pdf_data = base64.standard_b64encode(httpx.get(pdf_url).content).decode(\"utf-8\")\n",
    "\n",
    "# Alternative: Load from a local file\n",
    "# with open(\"document.pdf\", \"rb\") as f:\n",
    "#     pdf_data = base64.standard_b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# Send to Claude using base64 encoding\n",
    "client = anthropic.Anthropic()\n",
    "message = client.messages.create(\n",
    "    model=\"claude-opus-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"application/pdf\",\n",
    "                        \"data\": pdf_data\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"What are the key findings in this document?\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload a file using the Files API.\n",
    "\n",
    "This can come in handy when you want to pass the same file multiple times, for example in a conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'file_011CPgExGwFULN5meW8kjXCx',\n",
       " 'created_at': datetime.datetime(2025, 5, 31, 20, 30, 11, 980000, tzinfo=datetime.timezone.utc),\n",
       " 'filename': 'document.pdf',\n",
       " 'mime_type': 'application/pdf',\n",
       " 'size_bytes': 1042289,\n",
       " 'type': 'file',\n",
       " 'downloadable': False}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = anthropic.Anthropic()\n",
    "file = client.beta.files.upload(\n",
    "  file=(\"document.pdf\", open(\"./assets/gameboy_color.pdf\", \"rb\"), \"application/pdf\"),\n",
    ")\n",
    "\n",
    "file.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BetaMessage(id='msg_016KZzvDMArTnaxFztW1dSbS', container=None, content=[BetaTextBlock(citations=None, text=\"This is an instruction manual for the Nintendo Game Boy Color video game system. Here's a summary of the key contents:\\n\\n## Overview\\nThe manual provides setup and operating instructions for the Game Boy Color, which features a reflective TFT color display and is compatible with both original Game Boy games and new color games.\\n\\n## Main Sections Include:\\n\\n**Setup & Components**\\n- Lists all included components (system, wrist strap, power indicator, volume controls, etc.)\\n- Battery installation instructions (requires 2 AA batteries)\\n- Power and basic operation guidance\\n\\n**Game Compatibility**\\n- Three types of Game Paks work with the system:\\n  - Original Game Boy games (grayscale, with color palettes available)\\n  - Dual-mode games (enhanced colors on Game Boy Color)\\n  - Game Boy Color exclusive games (full color, won't work on original Game Boy)\\n\\n**Key Features**\\n- Instructions for changing screen color palettes on original Game Boy games\\n- Two-player gameplay using Game Link Cable or Communication Port\\n- External power supply compatibility\\n- Rechargeable battery pack warnings (incompatible)\\n\\n**Support Information**\\n- Troubleshooting guide for common issues\\n- Parts list with order numbers and prices\\n- Warranty information\\n- Nintendo service contact details (1-800-255-3700)\\n\\nThe manual emphasizes safety precautions and proper care to ensure optimal performance and longevity of the gaming system.\", type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=BetaUsage(cache_creation=None, cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=3170, output_tokens=320, server_tool_use=None, service_tier='standard'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_016KZzvDMArTnaxFztW1dSbS',\n",
       " 'container': None,\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"This is an instruction manual for the Nintendo Game Boy Color video game system. Here's a summary of the key contents:\\n\\n## Overview\\nThe manual provides setup and operating instructions for the Game Boy Color, which features a reflective TFT color display and is compatible with both original Game Boy games and new color games.\\n\\n## Main Sections Include:\\n\\n**Setup & Components**\\n- Lists all included components (system, wrist strap, power indicator, volume controls, etc.)\\n- Battery installation instructions (requires 2 AA batteries)\\n- Power and basic operation guidance\\n\\n**Game Compatibility**\\n- Three types of Game Paks work with the system:\\n  - Original Game Boy games (grayscale, with color palettes available)\\n  - Dual-mode games (enhanced colors on Game Boy Color)\\n  - Game Boy Color exclusive games (full color, won't work on original Game Boy)\\n\\n**Key Features**\\n- Instructions for changing screen color palettes on original Game Boy games\\n- Two-player gameplay using Game Link Cable or Communication Port\\n- External power supply compatibility\\n- Rechargeable battery pack warnings (incompatible)\\n\\n**Support Information**\\n- Troubleshooting guide for common issues\\n- Parts list with order numbers and prices\\n- Warranty information\\n- Nintendo service contact details (1-800-255-3700)\\n\\nThe manual emphasizes safety precautions and proper care to ensure optimal performance and longevity of the gaming system.\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation': None,\n",
       "  'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 3170,\n",
       "  'output_tokens': 320,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.beta.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Please summarize this document for me.\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"document\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"file\",\n",
    "                        \"file_id\": file.id\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    betas=[\"files-api-2025-04-14\"],\n",
    ")\n",
    "print(response)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex AI Hosting\n",
    "\n",
    "### Setup and Authentication\n",
    "Vertex AI requires Google Cloud project configuration and regional settings.\n",
    "\n",
    "### Key Differences:\n",
    "- **Project ID**: Must specify your Google Cloud project\n",
    "- **Region**: Choose deployment region for compliance/latency\n",
    "- **Model Names**: Slightly different naming convention with `@` version suffix\n",
    "- **Enterprise Features**: VPC integration, audit logging, and enterprise security\n",
    "\n",
    "### Available Regions:\n",
    "- `us-central1` - United States (primary)\n",
    "- `us-east4` - United States (secondary)\n",
    "- `europe-west1` - Europe (primary)\n",
    "- See [Vertex AI Locations](https://cloud.google.com/vertex-ai/docs/general/locations) for complete list\n",
    "\n",
    "### Resources:\n",
    "- [Anthropic on Vertex AI Documentation](https://docs.anthropic.com/en/api/claude-on-vertex-ai)\n",
    "- [Google Cloud Vertex AI](https://cloud.google.com/vertex-ai)\n",
    "- [Model Garden](https://console.cloud.google.com/vertex-ai/model-garden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Vertex AI Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Vertex AI:\n",
      "  Project: vectrix-401014\n",
      "  Region: europe-west1\n",
      "\n",
      "=== Vertex AI Response ===\n",
      "Model: claude-sonnet-4-20250514\n",
      "Content: Here are the key differences between using Vertex AI and direct Anthropic hosting for Claude:\n",
      "\n",
      "## **Vertex AI (Google Cloud)**\n",
      "\n",
      "**Pros:**\n",
      "- **Enterprise integration**: Seamlessly integrates with other Google Cloud services (BigQuery, Cloud Storage, etc.)\n",
      "- **Unified billing**: Single invoice for all Google Cloud services\n",
      "- **Enterprise controls**: Advanced IAM, logging, monitoring through Google Cloud Console\n",
      "- **Compliance**: Leverages Google\n",
      "Usage: 24 + 100 = 124 tokens\n",
      "\n",
      "=== Full Response Structure ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_vrtx_01Ei4SdeYxzbZg3S1qgeqKZm',\n",
       " 'content': [{'citations': None,\n",
       "   'text': 'Here are the key differences between using Vertex AI and direct Anthropic hosting for Claude:\\n\\n## **Vertex AI (Google Cloud)**\\n\\n**Pros:**\\n- **Enterprise integration**: Seamlessly integrates with other Google Cloud services (BigQuery, Cloud Storage, etc.)\\n- **Unified billing**: Single invoice for all Google Cloud services\\n- **Enterprise controls**: Advanced IAM, logging, monitoring through Google Cloud Console\\n- **Compliance**: Leverages Google',\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'max_tokens',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 24,\n",
       "  'output_tokens': 100,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': None}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anthropic import AnthropicVertex\n",
    "\n",
    "# Initialize Vertex AI client\n",
    "project_id = os.getenv(\"GCP_PROJECT_ID\")\n",
    "region = os.getenv(\"GCP_LOCATION\", \"us-central1\")  # Default to us-central1\n",
    "\n",
    "print(f\"Connecting to Vertex AI:\")\n",
    "print(f\"  Project: {project_id}\")\n",
    "print(f\"  Region: {region}\")\n",
    "\n",
    "vertex_client = AnthropicVertex(project_id=project_id, region=region)\n",
    "\n",
    "# Note: Vertex AI uses @ notation for model versions\n",
    "vertex_response = vertex_client.messages.create(\n",
    "    model=\"claude-sonnet-4@20250514\",\n",
    "    max_tokens=100,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello! Explain the difference between Vertex AI and direct Anthropic hosting.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"\\n=== Vertex AI Response ===\")\n",
    "print(f\"Model: {vertex_response.model}\")\n",
    "print(f\"Content: {vertex_response.content[0].text}\")\n",
    "print(f\"Usage: {vertex_response.usage.input_tokens} + {vertex_response.usage.output_tokens} = {vertex_response.usage.input_tokens + vertex_response.usage.output_tokens} tokens\")\n",
    "\n",
    "# Full response structure (same as direct Anthropic)\n",
    "print(\"\\n=== Full Response Structure ===\")\n",
    "vertex_response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertex AI Function Calling\n",
    "\n",
    "Function calling works identically on Vertex AI as with direct Anthropic hosting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vertex_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Function calling works the same on Vertex AI\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m vertex_tool_response = \u001b[43mvertex_client\u001b[49m.messages.create(\n\u001b[32m      3\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mclaude-sonnet-4@20250514\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     max_tokens=\u001b[32m1024\u001b[39m,\n\u001b[32m      5\u001b[39m     tools=[calculator_tool],  \u001b[38;5;66;03m# Same tool definition as before\u001b[39;00m\n\u001b[32m      6\u001b[39m     messages=[\n\u001b[32m      7\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mCalculate 42 divided by 7\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m      8\u001b[39m     ],\n\u001b[32m      9\u001b[39m     tool_choice= {\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtool\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mget_weather\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Vertex AI Tool Call ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvertex_tool_response.model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'vertex_client' is not defined"
     ]
    }
   ],
   "source": [
    "# Function calling works the same on Vertex AI\n",
    "vertex_tool_response = vertex_client.messages.create(\n",
    "    model=\"claude-sonnet-4@20250514\",\n",
    "    max_tokens=1024,\n",
    "    tools=[calculator_tool],  # Same tool definition as before\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Calculate 42 divided by 7\"}\n",
    "    ],\n",
    "    tool_choice={\"type\": \"tool\", \"name\": \"calculator\"}  # Must match the tool name\n",
    ")\n",
    "\n",
    "print(\"=== Vertex AI Tool Call ===\")\n",
    "print(f\"Model: {vertex_tool_response.model}\")\n",
    "\n",
    "for content in vertex_tool_response.content:\n",
    "    if content.type == \"text\":\n",
    "        print(f\"Text: {content.text}\")\n",
    "    elif content.type == \"tool_use\":\n",
    "        print(f\"Tool: {content.name}\")\n",
    "        print(f\"Operation: {content.input['operation']}\")\n",
    "        print(f\"Numbers: {content.input['a']} {content.input['operation']} {content.input['b']}\")\n",
    "\n",
    "print(f\"\\nâœ… Tool calling works identically on Vertex AI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Direct vs Vertex AI\n",
    "\n",
    "Let's compare the same request across both hosting options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Comparison: Direct vs Vertex AI ===\n",
      "\n",
      "ðŸ”µ Direct Anthropic:\n",
      "Model: claude-sonnet-4-20250514\n",
      "Response: Quantum computing harnesses quantum mechanics principles like superposition and entanglement to process information. Unlike classical bits (0 or 1), quantum bits (qubits) exist in multiple states simultaneously, enabling parallel computations. This allows quantum computers to potentially solve certain complex problems exponentially faster than classical computers, revolutionizing cryptography, optimization, and scientific simulation.\n",
      "Tokens: 18 + 79\n",
      "\n",
      "ðŸŸ¢ Vertex AI:\n",
      "Model: claude-sonnet-4-20250514\n",
      "Response: Quantum computing harnesses quantum mechanics principles like superposition and entanglement to process information. Unlike classical bits (0 or 1), quantum bits (qubits) exist in multiple states simultaneously, enabling parallel calculations. This allows quantum computers to solve certain complex problems exponentially faster than classical computers, particularly in cryptography, optimization, and simulation.\n",
      "Tokens: 18 + 75\n",
      "\n",
      "ðŸ’¡ Both use identical APIs and response formats!\n",
      "ðŸ’¡ Only differences: authentication method and model naming convention\n"
     ]
    }
   ],
   "source": [
    "test_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Explain quantum computing in exactly 50 words.\"}\n",
    "]\n",
    "\n",
    "print(\"=== Comparison: Direct vs Vertex AI ===\")\n",
    "\n",
    "# Direct Anthropic\n",
    "direct_response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=100,\n",
    "    messages=test_messages\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ”µ Direct Anthropic:\")\n",
    "print(f\"Model: {direct_response.model}\")\n",
    "print(f\"Response: {direct_response.content[0].text}\")\n",
    "print(f\"Tokens: {direct_response.usage.input_tokens} + {direct_response.usage.output_tokens}\")\n",
    "\n",
    "# Vertex AI\n",
    "vertex_response = vertex_client.messages.create(\n",
    "    model=\"claude-sonnet-4@20250514\",\n",
    "    max_tokens=100,\n",
    "    messages=test_messages\n",
    ")\n",
    "\n",
    "print(\"\\nðŸŸ¢ Vertex AI:\")\n",
    "print(f\"Model: {vertex_response.model}\")\n",
    "print(f\"Response: {vertex_response.content[0].text}\")\n",
    "print(f\"Tokens: {vertex_response.usage.input_tokens} + {vertex_response.usage.output_tokens}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Both use identical APIs and response formats!\")\n",
    "print(\"ðŸ’¡ Only differences: authentication method and model naming convention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### When to Use Direct Anthropic:\n",
    "- **Rapid prototyping** and development\n",
    "- **Latest model access** and features\n",
    "- **Simple deployment** requirements\n",
    "- **Global applications** without specific regional needs\n",
    "\n",
    "### When to Use Vertex AI:\n",
    "- **Enterprise deployments** with strict security requirements\n",
    "- **VPC integration** for network isolation\n",
    "- **Regional compliance** needs (data residency)\n",
    "- **Unified Google Cloud billing** and management\n",
    "- **Advanced monitoring** and audit logging requirements\n",
    "\n",
    "### Error Handling:\n",
    "```python\n",
    "try:\n",
    "    response = client.messages.create(...)  # or vertex_client\n",
    "except anthropic.APIError as e:\n",
    "    print(f\"API Error: {e}\")\n",
    "except anthropic.RateLimitError as e:\n",
    "    print(f\"Rate limit exceeded: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")\n",
    "```\n",
    "\n",
    "### Performance Tips:\n",
    "- **Choose appropriate max_tokens** based on your use case\n",
    "- **Use streaming** for long responses: `stream=True`\n",
    "- **Implement retry logic** for production applications\n",
    "- **Monitor token usage** to optimize costs\n",
    "\n",
    "## Summary\n",
    "\n",
    "âœ… **Identical APIs**: Both hosting options use the same Anthropic Python SDK  \n",
    "âœ… **Same Features**: Function calling, streaming, and all model capabilities work identically  \n",
    "âœ… **Flexible Deployment**: Choose based on your security, compliance, and infrastructure needs  \n",
    "âœ… **Enterprise Ready**: Vertex AI provides additional enterprise features when needed  \n",
    "\n",
    "Both direct Anthropic and Vertex AI hosting provide access to the same powerful Claude models with identical APIs, giving you flexibility in how you deploy and scale your applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
