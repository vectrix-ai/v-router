{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This notebook uses `await` syntax. Run it in a Jupyter environment with IPython kernel, or use `asyncio.run()` wrapper for regular Python scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Content with v-router üñºÔ∏è\n",
    "\n",
    "This notebook demonstrates how to use v-router with multimodal content (images, PDFs, and Word documents). The v-router library provides a unified interface for sending images and documents to different LLM providers.\n",
    "\n",
    "## Overview\n",
    "\n",
    "v-router supports:\n",
    "- **Images**: JPEG, PNG, GIF, WebP formats\n",
    "- **Documents**: PDF files and Word documents (.docx)\n",
    "- **Automatic conversion**: File paths are automatically converted to base64\n",
    "- **Unified interface**: Same API across all providers\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's set up our environment and imports:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start: Using Local Files\n",
    "\n",
    "The easiest way to send images and PDFs is by passing file paths directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:56:51,730 - v_router.router - INFO - Trying primary model: claude-3-5-sonnet-20241022 on anthropic\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Summary:\n",
      "[\"This is an instruction manual/booklet for the Nintendo Game Boy Color handheld video game system. The document covers various aspects including:\\n\\n1. Introduction to the system and its features\\n2. Components and parts identification\\n3. Basic setup and operation instructions\\n4. Battery installation and maintenance\\n5. Information about compatible Game Paks\\n6. Two-player gaming setup using Game Link Cable\\n7. Troubleshooting guide\\n8. Warranty information\\n9. Parts list and order form\\n\\nThe manual provides detailed technical specifications, safety warnings, and instructions for proper use of the Game Boy Color, which was a color screen upgrade to Nintendo's original Game Boy system. It includes diagrams and illustrations to help users understand the device's features and proper operation procedures.\\n\\nThe document appears to be an official Nintendo manual from when the Game Boy Color was released, containing all the necessary information for users to properly set up and maintain their device.\"]\n"
     ]
    }
   ],
   "source": [
    "# Example using the PDF file included in this repository\n",
    "from v_router import Client, LLM, HumanMessage\n",
    "\n",
    "\n",
    "# Create a client\n",
    "client = Client(\n",
    "    llm_config=LLM(\n",
    "        model_name=\"claude-3-5-sonnet-20241022\",\n",
    "        provider=\"anthropic\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Send a PDF file by just passing its path\n",
    "pdf_path = \"providers/assets/gameboy_color.pdf\"\n",
    "messages = [\n",
    "    HumanMessage(content=pdf_path),\n",
    "    HumanMessage(content=\"What is this document about? Give me a brief summary.\"),\n",
    "]\n",
    "\n",
    "response = await client.messages.create(messages=messages, max_tokens=200)\n",
    "print(\"PDF Summary:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending Images\n",
    "\n",
    "### Method 1: Base64 Encoded Images\n",
    "\n",
    "You can send images by providing base64-encoded data directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import httpx\n",
    "from pathlib import Path\n",
    "\n",
    "# Import content types if you need to create multimodal messages manually\n",
    "from v_router.classes.messages import TextContent, ImageContent, DocumentContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:57:19,812 - v_router.router - INFO - Trying primary model: claude-3-5-sonnet-20241022 on anthropic\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic Response:\n",
      "[\"This image shows a carpenter ant (genus Camponotus) in striking detail. The ant is captured in a dynamic pose, appearing to be rearing up on its hind legs, which is a common defensive posture. The ant's characteristic features are clearly visible, including its segmented body, long antennae, and powerful mandibles. The photo has a shallow depth of field, creating a beautifully blurred background that makes the ant stand out in sharp focus. The ant appears to be dark in color, possibly black or dark brown, and its exoskeleton has a slight sheen to it. Carpenter ants are among the larger ant species, and this image really showcases their impressive size and structure. The lighting in the photo gives it a warm, natural tone and helps highlight the ant's distinctive anatomy.\"]\n"
     ]
    }
   ],
   "source": [
    "# Download a sample image\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Camponotus_flavomarginatus_ant.jpg/320px-Camponotus_flavomarginatus_ant.jpg\"\n",
    "response = httpx.get(image_url)\n",
    "image_data = base64.b64encode(response.content).decode(\"utf-8\")\n",
    "\n",
    "# Create a client with Anthropic\n",
    "client = Client(\n",
    "    llm_config=LLM(\n",
    "        model_name=\"claude-3-5-sonnet-20241022\",\n",
    "        provider=\"anthropic\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Send multimodal message\n",
    "messages = [\n",
    "    HumanMessage(content=[\n",
    "        TextContent(text=\"What animal is in this image? Describe it in detail.\"),\n",
    "        ImageContent(data=image_data, media_type=\"image/jpeg\")\n",
    "    ])\n",
    "]\n",
    "\n",
    "response = await client.messages.create(messages=messages, max_tokens=200)\n",
    "print(\"Anthropic Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: File Path (Automatic Conversion)\n",
    "\n",
    "v-router can automatically convert local image files to base64:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:57:32,364 - v_router.router - INFO - Trying primary model: claude-3-5-sonnet-20241022 on anthropic\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response from file path:\n",
      "[\"This is a detailed macro photograph of an ant, showing its distinctive features like its segmented body, long antennae, and slender legs. The ant appears to be in a rearing or defensive posture, with its front legs raised off the ground. The image has a shallow depth of field, creating a soft, blurred background while keeping the ant in sharp focus. The lighting gives the photograph a warm, brownish tone, and the detail captured allows you to see the ant's\"]\n"
     ]
    }
   ],
   "source": [
    "# Save the image locally\n",
    "image_path = Path(\"/tmp/test_ant.jpg\")\n",
    "# Use the httpx response from earlier, not the v-router response\n",
    "with open(image_path, \"wb\") as f:\n",
    "    f.write(httpx.get(image_url).content)\n",
    "\n",
    "# Send using file path - v-router will automatically convert to base64\n",
    "messages = [\n",
    "    HumanMessage(content=str(image_path))  # Just pass the file path as a string\n",
    "]\n",
    "\n",
    "response = await client.messages.create(messages=messages, max_tokens=100)\n",
    "print(\"Response from file path:\")\n",
    "print(response.content)\n",
    "\n",
    "# Clean up\n",
    "image_path.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Provider Compatibility\n",
    "\n",
    "The same multimodal content works across different providers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:57:41,890 - v_router.router - INFO - Trying primary model: claude-3-5-sonnet-20241022 on anthropic\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANTHROPIC (claude-3-5-sonnet-20241022):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:57:44,749 - v_router.router - INFO - Trying primary model: gemini-1.5-flash on google\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ['This is a detailed macro photograph of an ant, showing its distinctive features like its segmented body, thin legs, and antennae. The ant appears to be in a rearing or alert posture, with its front legs raised off the surface']\n",
      "\n",
      "GOOGLE (gemini-1.5-flash):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:57:46,045 - v_router.router - INFO - Trying primary model: gpt-4o on openai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì [\"That's a close-up image of a carpenter ant (genus *Camponotus*) carrying something.  Specifically, it appears to be carrying another, smaller insect or possibly a piece of food.  The ant is black and its body is\"]\n",
      "\n",
      "OPENAI (gpt-4o):\n",
      "‚úì ['The image shows a close-up of an ant standing on a surface. The ant appears to be in a defensive or alert posture, with its body raised and legs spread. The background is blurred, focusing attention on the ant.']\n"
     ]
    }
   ],
   "source": [
    "# Prepare the same multimodal message\n",
    "multimodal_messages = [\n",
    "    HumanMessage(content=[\n",
    "        TextContent(text=\"What do you see in this image?\"),\n",
    "        ImageContent(data=image_data, media_type=\"image/jpeg\")\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Test with different providers\n",
    "providers = [\n",
    "    (\"anthropic\", \"claude-3-5-sonnet-20241022\"),\n",
    "    (\"google\", \"gemini-1.5-flash\"),\n",
    "    (\"openai\", \"gpt-4o\")\n",
    "]\n",
    "\n",
    "for provider, model in providers:\n",
    "    print(f\"\\n{provider.upper()} ({model}):\")\n",
    "    try:\n",
    "        client = Client(\n",
    "            llm_config=LLM(\n",
    "                model_name=model,\n",
    "                provider=provider\n",
    "            )\n",
    "        )\n",
    "        response = await client.messages.create(messages=multimodal_messages, max_tokens=50)\n",
    "        print(f\"‚úì {response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Documents (.docx)\n",
    "\n",
    "v-router supports Word documents (.docx) by automatically converting them to HTML using the mammoth library. This works across all providers by sending the converted content as text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: File Path (Automatic Conversion)\n",
    "\n",
    "The easiest way to send Word documents is by passing the file path directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:58:10,229 - v_router.router - INFO - Trying primary model: claude-3-5-sonnet-20241022 on anthropic\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Document Summary:\n",
      "['This is a Purchase Order (PO) document with PO number 23781 for automotive parts. The customer, John Smith from Redline Auto Center in Lansing, Michigan, is ordering the following items:\\n\\n1. 4 units of Brake Discs, Pads & Calipers at $111.36 each\\n2. 2 units of Control Arm at $60.93 each\\n3. 2 units of Suspension Lift Kit at $399.83 each\\n\\nThe subtotal is $1,366.96, with a 10% discount, 12% sales tax, additional costs for shipping & handling ($800) and other costs ($500), bringing the total amount to $2,694.30. The payment terms indicate that payment is due 30 days upon receipt of the items, and shipping terms are Freight on Board via Air & Land shipping method.']\n"
     ]
    }
   ],
   "source": [
    "# Example using the Word document included in this repository\n",
    "from v_router import Client, LLM\n",
    "\n",
    "# Create a client\n",
    "client = Client(\n",
    "    llm_config=LLM(\n",
    "        model_name=\"claude-3-5-sonnet-20241022\",\n",
    "        provider=\"anthropic\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Send a Word document by just passing its path\n",
    "docx_path = \"providers/assets/order.docx\"\n",
    "messages = [\n",
    "    HumanMessage(content=docx_path),\n",
    "    HumanMessage(content=\"What is this document about? Give me a brief summary.\")\n",
    "]\n",
    "\n",
    "response = await client.messages.create(messages=messages, max_tokens=200)\n",
    "print(\"Word Document Summary:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Base64 Encoded Word Documents\n",
    "\n",
    "You can also send Word documents by providing base64-encoded data directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:58:21,072 - v_router.router - INFO - Trying primary model: gpt-4.1-mini on openai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Document Analysis:\n",
      "['Based on the content and structure of the provided document, this is a **Purchase Order**.\\n\\n### Key indicators:\\n- The document title explicitly states **\"PURCHASE ORDER\"**.\\n- It contains typical purchase order elements such as:\\n  - **Company and vendor information** (names, addresses, contact details).\\n  - **Purchase Order Number** and **Date**.\\n  - Sections labeled **Vendor** and **Customer**.\\n  - A detailed **itemized list** with columns for:\\n    - Product Code\\n    - Product Description\\n    - Quantity\\n    - Unit Price\\n    - Amount\\n  - Shipping terms and methods.\\n  - Financial summary including:\\n    - Subtotal\\n    - Discount\\n    - Sales Tax\\n    - Other Costs\\n    - Shipping & Handling\\n    - Total Amount\\n  - Payment terms note (\"Payment shall be 30 days upon receipt of the items above.\")\\n\\n### Conclusion:\\nThis document is a **Purchase Order (PO)** used by']\n"
     ]
    }
   ],
   "source": [
    "# Load and encode a Word document\n",
    "with open(\"providers/assets/order.docx\", \"rb\") as f:\n",
    "    docx_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# Create a client with Anthropic\n",
    "client = Client(\n",
    "    llm_config=LLM(\n",
    "        model_name=\"gpt-4.1-mini\",\n",
    "        provider=\"openai\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Send multimodal message with Word document\n",
    "messages = [\n",
    "    HumanMessage(content=[\n",
    "        TextContent(text=\"Please analyze this Word document and tell me what type of document it is.\"),\n",
    "        DocumentContent(\n",
    "            data=docx_data, \n",
    "            media_type=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
    "        )\n",
    "    ])\n",
    "    ]\n",
    "\n",
    "response = await client.messages.create(messages=messages, max_tokens=200)\n",
    "print(\"Word Document Analysis:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Provider Word Document Support\n",
    "\n",
    "Word documents work across all providers through automatic HTML conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:58:30,062 - v_router.router - INFO - Trying primary model: claude-3-5-sonnet-20241022 on anthropic\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANTHROPIC (claude-3-5-sonnet-20241022):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:58:33,561 - v_router.router - INFO - Trying primary model: gemini-1.5-flash on google\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì ['This is a Purchase Order (PO) document. This can be clearly seen in the header of the document where \"PURCHASE ORDER\" is prominently displayed, and it contains typical purchase order elements such as:\\n\\n1. PO Number (']\n",
      "\n",
      "GOOGLE (gemini-1.5-flash):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:58:34,396 - v_router.router - INFO - Trying primary model: gpt-4o on openai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì [\"This is a **Purchase Order (PO)**.  It's a commercial document issued by a buyer (Redline Auto Center in this case) to a seller (the company whose details are at the top) for the purchase of goods or services\"]\n",
      "\n",
      "OPENAI (gpt-4o):\n",
      "‚úì ['The document you provided is a \"Purchase Order.\" A purchase order is a commercial document issued by a buyer to a seller, indicating the types, quantities, and agreed prices for products or services the seller will provide to the buyer. It serves as an']\n"
     ]
    }
   ],
   "source": [
    "# Prepare the same Word document message\n",
    "word_doc_messages = [\n",
    "    HumanMessage(content=[\n",
    "        TextContent(text=\"What type of document is this?\"),\n",
    "        DocumentContent(\n",
    "            data=docx_data, \n",
    "            media_type=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
    "        )\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Test with different providers\n",
    "providers = [\n",
    "    (\"anthropic\", \"claude-3-5-sonnet-20241022\"),\n",
    "    (\"google\", \"gemini-1.5-flash\"),\n",
    "    (\"openai\", \"gpt-4o\")\n",
    "]\n",
    "\n",
    "for provider, model in providers:\n",
    "    print(f\"\\n{provider.upper()} ({model}):\")\n",
    "    try:\n",
    "        client = Client(\n",
    "            llm_config=LLM(\n",
    "                model_name=model,\n",
    "                provider=provider\n",
    "            )\n",
    "        )\n",
    "        response = await client.messages.create(messages=word_doc_messages, max_tokens=50)\n",
    "        print(f\"‚úì {response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Multimodal Messages with Word Documents\n",
    "\n",
    "You can combine Word documents with images and other content types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:58:49,641 - v_router.router - INFO - Trying primary model: claude-3-5-sonnet-20241022 on anthropic\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Content Analysis:\n",
      "[\"Let me describe both documents:\\n\\n1. The Word document appears to be a purchase order template with the following key elements:\\n- Header section for company details\\n- PO Number: 23781\\n- Vendor and customer information sections\\n- Shipping terms: Freight on Board\\n- Shipping method: Air & Land\\n- Product list with 3 automotive parts (brake components, control arm, suspension kit)\\n- Pricing calculations including subtotal, discount, tax, shipping and handling\\n- Total amount: $2,694.30\\n- Payment terms of 30 days\\n\\n2. The image shows a close-up macro photograph of an ant in a dramatic pose. The ant appears to be standing on a textured surface, and the photo captures fine details of the ant's body structure, including its antennae and legs. The background has a soft, blurred reddish tone while the ant is in sharp focus.\"]\n"
     ]
    }
   ],
   "source": [
    "# Create a complex multimodal message with multiple content types\n",
    "complex_messages = [\n",
    "    HumanMessage(content=[\n",
    "            TextContent(text=\"I'm sharing multiple documents with you:\"),\n",
    "            TextContent(text=\"1. A Word document:\"),\n",
    "            DocumentContent(\n",
    "                data=docx_data, \n",
    "                media_type=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
    "            ),\n",
    "            TextContent(text=\"2. An image:\"),\n",
    "            ImageContent(data=image_data, media_type=\"image/jpeg\"),\n",
    "            TextContent(text=\"Can you briefly describe what each contains?\")\n",
    "        ])\n",
    "]\n",
    "\n",
    "try:\n",
    "    client = Client(\n",
    "        llm_config=LLM(\n",
    "            model_name=\"claude-3-5-sonnet-20241022\",\n",
    "            provider=\"anthropic\"\n",
    "        )\n",
    "    )\n",
    "    response = await client.messages.create(messages=complex_messages, max_tokens=300)\n",
    "    print(\"Multi-Content Analysis:\")\n",
    "    print(response.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error with complex message: {e}\")\n",
    "    print(\"\\nTrying with a simpler Word document message...\")\n",
    "    \n",
    "    # Fallback to a simpler message\n",
    "    simple_messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                TextContent(text=\"What type of document is this?\"),\n",
    "                DocumentContent(\n",
    "                    data=docx_data, \n",
    "                    media_type=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    response = await client.messages.create(messages=simple_messages, max_tokens=100)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Documents\n",
    "\n",
    "Some providers (like Anthropic and Google) support PDF documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:58:57,435 - v_router.router - INFO - Trying primary model: gpt-4o on openai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Analysis:\n",
      "[\"The PDF is an instruction booklet for the Game Boy Color. Here's a summary of its contents:\\n\\n1. **Introduction**: Overview of the Game Boy Color video game system and its features.\\n\\n2. **List of Components**: Diagram and description of the Game Boy Color's parts, including the communication port, power indicator, and buttons.\\n\\n3. **Description of Components**: Detailed explanation of each component's function.\\n\\n4. **Installing Batteries**: Instructions on how to insert batteries into the device.\\n\\n5. **Caution**: Warning against using the Game Boy Rechargeable Battery Pack.\\n\\n6. **About Game Boy Color Game Paks**: Information on different types of game paks compatible with the system.\\n\\n7. **Using the Game Boy Color**: Steps to insert and play a game pak.\\n\\n8. **Changing the Screen Color**: Instructions on how to change screen colors for original Game Boy game paks.\\n\\n9. **Two-Player Mode Using the Game Link Cable**\"]\n"
     ]
    }
   ],
   "source": [
    "with open(\"providers/assets/gameboy_color.pdf\", \"rb\") as f:\n",
    "    pdf_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# Send PDF to OpenAI\n",
    "anthropic_client = Client(\n",
    "    llm_config=LLM(\n",
    "        model_name=\"gpt-4o\",\n",
    "        provider=\"openai\"\n",
    "    )\n",
    ")\n",
    "\n",
    "pdf_messages = [\n",
    "    HumanMessage(content=[\n",
    "        TextContent(text=\"Explain what is in this PDF\"),\n",
    "        DocumentContent(data=pdf_data, media_type=\"application/pdf\")\n",
    "    ])\n",
    "]\n",
    "\n",
    "response = await anthropic_client.messages.create(messages=pdf_messages, max_tokens=200)\n",
    "print(\"PDF Analysis:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex Multimodal Conversations\n",
    "\n",
    "You can combine multiple images and text in a single message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-13 15:59:23,017 - v_router.router - INFO - Trying primary model: gpt-4o on openai\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Response:\n",
      "['The first image shows an ant, likely a jumping ant, standing on a surface. It has a black body and is raising its front legs.\\n\\nThe second image features a ginger cat with orange fur and striking yellow eyes, looking directly at the camera. The background is slightly blurred.']\n"
     ]
    }
   ],
   "source": [
    "# Use the ant image from earlier and download a new one\n",
    "image1_data = image_data  # Reuse the ant image from earlier\n",
    "\n",
    "# Download a different image\n",
    "image2_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/320px-Cat03.jpg\"\n",
    "try:\n",
    "    image2_response = httpx.get(image2_url)\n",
    "    image2_data = base64.b64encode(image2_response.content).decode(\"utf-8\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to download second image: {e}\")\n",
    "    # Use a simple fallback example\n",
    "    image2_data = image1_data\n",
    "\n",
    "# Create a complex multimodal message\n",
    "complex_messages = [\n",
    "    HumanMessage(content=[\n",
    "            TextContent(text=\"I'm going to show you two images.\"),\n",
    "            TextContent(text=\"First image:\"),\n",
    "            ImageContent(data=image1_data, media_type=\"image/jpeg\"),\n",
    "            TextContent(text=\"Second image:\"),\n",
    "            ImageContent(data=image2_data, media_type=\"image/jpeg\"),\n",
    "            TextContent(text=\"Can you describe what you see in each image?\")\n",
    "        ])\n",
    "]\n",
    "\n",
    "try:\n",
    "    response = await anthropic_client.messages.create(messages=complex_messages, max_tokens=300)\n",
    "    print(\"Comparison Response:\")\n",
    "    print(response.content)\n",
    "except Exception as e:\n",
    "    print(f\"Error with complex message: {e}\")\n",
    "    print(\"\\nTrying with a simpler message...\")\n",
    "    \n",
    "    # Fallback to a simpler message\n",
    "    simple_messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": [\n",
    "                TextContent(text=\"What do you see in this image?\"),\n",
    "                ImageContent(data=image1_data, media_type=\"image/jpeg\")\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    response = await anthropic_client.messages.create(messages=simple_messages, max_tokens=100)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provider-Specific Considerations\n",
    "\n",
    "### Anthropic\n",
    "- Supports: Images (JPEG, PNG, GIF, WebP), PDFs, and Word documents (.docx)\n",
    "- Max image size: 5MB per image\n",
    "- Multiple images per message: Yes\n",
    "- Word documents: Converted to HTML automatically\n",
    "\n",
    "### Google (Gemini)\n",
    "- Supports: Images, PDFs, and Word documents (.docx)\n",
    "- Processes images through `inline_data`\n",
    "- Multiple images per message: Yes\n",
    "- Word documents: Converted to HTML automatically\n",
    "\n",
    "### OpenAI\n",
    "- Supports: Images and Word documents (.docx)\n",
    "- Uses data URI format for images\n",
    "- Multiple images per message: Yes\n",
    "- Word documents: Converted to HTML automatically\n",
    "- Note: PDFs will show a placeholder message\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Image Optimization**: Resize large images before sending to reduce latency\n",
    "2. **Error Handling**: Always handle provider-specific limitations\n",
    "3. **Fallback Strategy**: Use v-router's fallback mechanism for providers that don't support certain content types\n",
    "4. **Content Validation**: Ensure your content matches supported MIME types\n",
    "5. **Word Document Format**: Use .docx format (not .doc) for best compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Building a Visual Question Answering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_image(image_path: str, question: str, provider: str = \"anthropic\"):\n",
    "    \"\"\"Analyze an image and answer a question about it.\"\"\"\n",
    "    \n",
    "    # Read and encode the image\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        image_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    \n",
    "    # Determine MIME type\n",
    "    import mimetypes\n",
    "    mime_type, _ = mimetypes.guess_type(image_path)\n",
    "    \n",
    "    # Create client with fallback\n",
    "    client = Client(\n",
    "        llm_config=LLM(\n",
    "            model_name=\"claude-3-5-sonnet-20241022\" if provider == \"anthropic\" else \"gpt-4o\",\n",
    "            provider=provider,\n",
    "            try_other_providers=True  # Enable cross-provider fallback\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Send the question with the image\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                TextContent(text=question),\n",
    "                ImageContent(data=image_data, media_type=mime_type or \"image/jpeg\")\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = await client.messages.create(messages=messages, max_tokens=300)\n",
    "    return response.content\n",
    "\n",
    "# Example usage (you would need to provide an actual image path)\n",
    "# result = await analyze_image(\"/path/to/image.jpg\", \"What objects can you identify in this image?\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "v-router makes it easy to work with multimodal content across different LLM providers:\n",
    "\n",
    "- **Unified API**: Same interface for all providers\n",
    "- **Automatic conversion**: File paths are converted to base64 automatically\n",
    "- **Word document support**: .docx files are automatically converted to HTML using mammoth\n",
    "- **Provider abstraction**: Handle provider differences transparently\n",
    "- **Fallback support**: Automatically try other providers if one fails\n",
    "\n",
    "This enables you to build robust multimodal applications without worrying about provider-specific implementation details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
