{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36183997",
   "metadata": {},
   "source": [
    "# Provider Packages ðŸ“¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edea794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bb253",
   "metadata": {},
   "source": [
    "## Anthropic\n",
    "### General hosting via Anthropic\n",
    "Note that it will **by default take the enviroment variable ANTHROPIC_API_KEY** as API key\n",
    "\n",
    "- Python SDK Docs: https://github.com/anthropics/anthropic-sdk-python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be232aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextBlock(citations=None, text=\"Hello! It's nice to meet you. How are you doing today? Is there anything I can help you with or anything you'd like to chat about?\", type='text')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n",
    "    ]\n",
    ")\n",
    "message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d688c",
   "metadata": {},
   "source": [
    "### Hosting via VertexAI (Google Cloud)\n",
    "Here it's important to always specify the project ID from your Google Cloud project and the region where you want to model from what region you want to run inferance on.\n",
    "\n",
    "- Check the [Vertex AI Locations](https://cloud.google.com/vertex-ai/docs/general/locations) for more information about the specifc regions.\n",
    "- The Python SDK information: https://docs.anthropic.com/en/api/claude-on-vertex-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459f701e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(id='msg_vrtx_01DJ9ceh5Woq1YbiETLde7iy', content=[TextBlock(citations=None, text=\"Hello! It's nice to meet you. How are you doing today? Is there anything I can help you with?\", type='text')], model='claude-sonnet-4-20250514', role='assistant', stop_reason='end_turn', stop_sequence=None, type='message', usage=Usage(cache_creation_input_tokens=0, cache_read_input_tokens=0, input_tokens=10, output_tokens=27, server_tool_use=None, service_tier=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anthropic import AnthropicVertex\n",
    "\n",
    "project_id = os.getenv(\"GCP_PROJECT_ID\")\n",
    "# Where the model is running\n",
    "region = os.getenv(\"GCP_LOCATION\")\n",
    "client = AnthropicVertex(project_id=project_id, region=region)\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4@20250514\",\n",
    "    max_tokens=100,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hey Claude!\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c73b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Hello! It's nice to meet you.\n",
      "Model: claude-sonnet-4-20250514\n",
      "Provider: anthropic\n",
      "--------------------------------\n",
      "Response: Hello! It's nice to meet you.\n",
      "Model: claude-sonnet-4-20250514\n",
      "Provider: vertexai\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278b355",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "### General hosting via OpenAI\n",
    "Note that **it will take by default the enviroment variable OPENAI_API_KEY** as API KEY\n",
    "\n",
    "- [Python SDK Docs](https://platform.openai.com/docs/libraries?language=python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f13b0a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_68338a0a413881918447b5f0429ad9ea0f5635c39fdbce5d', created_at=1748208138.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_68338a0ad5948191a39c5d2d916a91c90f5635c39fdbce5d', content=[ResponseOutputText(annotations=[], text='Under a blanket of twinkling stars, a gentle unicorn named Luna danced through a moonlit meadow, spreading dreams of magic and wonder to all the sleeping children.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=18, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=34, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=52), user=None, store=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c191f",
   "metadata": {},
   "source": [
    "### Hosting via Azure\n",
    "\n",
    "Check the documentation [here](https://learn.microsoft.com/en-gb/azure/ai-services/openai/supported-languages?tabs=dotnet-secure%2Csecure%2Cpython-key%2Ccommand&pivots=programming-language-pythong)\n",
    "\n",
    "Note that not all models are available in every region, most EU models are available in **swedencentral** and US models in **eastus2**\n",
    "Also remember to deploy the model you want to use on https://ai.azure.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2ef3fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BbDP4mzds7ERyNEmV1yN8Rit610Oq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='To **output all files in a directory using Python**, you have several options depending on your needs and Python version.\\n\\n### **1. Using `os.listdir`**  \\nThis lists all files and subdirectories. To filter only files:\\n\\n```python\\nimport os\\n\\ndirectory = \\'/path/to/directory\\'\\n\\nfor entry in os.listdir(directory):\\n    if os.path.isfile(os.path.join(directory, entry)):\\n        print(entry)\\n```\\n\\n---\\n\\n### **2. Using `os.scandir`** (**Python 3.5+**, more efficient):\\n\\n```python\\nimport os\\n\\ndirectory = \\'/path/to/directory\\'\\n\\nwith os.scandir(directory) as entries:\\n    for entry in entries:\\n        if entry.is_file():\\n            print(entry.name)\\n```\\n\\n---\\n\\n### **3. Using `glob`** (matches file patterns):\\n\\n```python\\nimport glob\\n\\ndirectory = \\'/path/to/directory\\'\\n\\nfor filepath in glob.glob(f\"{directory}/*\"):\\n    if os.path.isfile(filepath):\\n        print(os.path.basename(filepath))\\n```\\n\\n---\\n\\n### **4. Using `pathlib`** (modern, Python 3.4+):\\n\\n```python\\nfrom pathlib import Path\\n\\ndirectory = Path(\\'/path/to/directory\\')\\n\\nfor file in directory.iterdir():\\n    if file.is_file():\\n        print(file.name)\\n```\\n\\n---\\n\\n> **Replace** `\\'/path/to/directory\\'` **with your actual directory path.**\\n\\n---\\n\\n### **Summary Table**\\n\\n| Method        | Module    | Python Version | Recommended?        |\\n|---------------|-----------|---------------|---------------------|\\n| os.listdir    | `os`      | All           | Simple, basic       |\\n| os.scandir    | `os`      | 3.5+          | Fast & efficient    |\\n| glob          | `glob`    | All           | For pattern matching|\\n| pathlib       | `pathlib` | 3.4+          | Modern, clean code  |\\n\\nLet me know if you want to **list files recursively** (including subfolders)!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1748209358, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier=None, system_fingerprint='fp_07e970ab25', usage=CompletionUsage(completion_tokens=413, prompt_tokens=19, total_tokens=432, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2025-01-01-preview\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",  # e.g. gpt-35-instant\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do I output all files in a directory using Python?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4387c",
   "metadata": {},
   "source": [
    "## Google\n",
    "### General Hosting (via AI Studio)\n",
    "\n",
    "- Check the documentation on GitHub [here](https://github.com/googleapis/python-genai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ccb4e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown of why:\\n\\n*   **Sunlight:** Sunlight is actually white light, which is made up of all the colors of the rainbow.\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n*   **Scattering:** This collision causes the light to scatter in different directions.\\n*   **Rayleigh Scattering and Wavelength:** Rayleigh scattering is more effective at shorter wavelengths. Blue and violet light have shorter wavelengths than other colors like red and orange.\\n*   **Why Blue Instead of Violet?:** Although violet light has an even shorter wavelength than blue, the sun emits less violet light, and our eyes are more sensitive to blue light.\\n*   **Therefore:** Blue and violet light are scattered much more strongly than other colors. This scattered blue light is what we see when we look up at the sky on a sunny day.\\n\\n**In Simple Terms:**\\n\\nImagine throwing different sized balls at a bunch of small obstacles. The smaller balls (blue and violet light) will bounce off in all directions more easily than the bigger balls (red and orange light).\\n\\n**Why Sunsets are Red/Orange:**\\n\\nWhen the sun is low on the horizon (during sunrise or sunset), sunlight has to travel through much more of the atmosphere to reach our eyes. During this long journey, most of the blue light has been scattered away. The longer wavelengths, like red and orange, are able to pass through the atmosphere more easily, so those are the colors we see.\\n\")], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.2641108498644473, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=None, response_id=None, model_version='gemini-2.0-flash-001', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=335, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=335)], prompt_token_count=6, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=6)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=341, traffic_type=None), automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001', contents='Why is the sky blue?'\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33153af",
   "metadata": {},
   "source": [
    "### Hosting via VertexAI\n",
    "We do this using the same package as before but we now set the project id and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e08ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text=\"The sky is blue because of a phenomenon called **Rayleigh scattering**. Here's the breakdown:\\n\\n*   **Sunlight is composed of all colors:** White sunlight is actually a mixture of all the colors of the rainbow.\\n\\n*   **Light waves interact with air molecules:** As sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Shorter wavelengths scatter more:** Rayleigh scattering is the scattering of electromagnetic radiation (including visible light) by particles of a much smaller wavelength. Shorter wavelengths of light (blue and violet) are scattered much more strongly than longer wavelengths (red and orange).\\n\\n*   **Blue is scattered the most:** Blue light has a shorter wavelength than red light. Therefore, blue light is scattered about ten times more efficiently than red light.\\n\\n*   **We see the scattered blue light:** This scattered blue light is what we see when we look up at the sky.\\n\\n**Why not violet?**\\n\\nViolet light has an even shorter wavelength than blue light, so it is scattered even more. However, the sun emits less violet light than blue light, and our eyes are also less sensitive to violet. As a result, the sky appears blue rather than violet.\\n\\n**In summary:** Sunlight hits the atmosphere, blue light is scattered more than other colors, and that scattered blue light is what we see.\\n\")], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=394, license=None, publication_date=None, start_index=260, title=None, uri=None), Citation(end_index=543, license=None, publication_date=None, start_index=412, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.22066311785694567, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=datetime.datetime(2025, 5, 25, 21, 54, 20, 40003, tzinfo=TzInfo(UTC)), response_id='jJEzaMO4AojXvdIPzNjO6AQ', model_version='gemini-2.0-flash-001', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=283, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=283)], prompt_token_count=6, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=6)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=289, traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>), automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# Only run this block for Vertex AI API\n",
    "client = genai.Client(\n",
    "    vertexai=True, project=os.environ[\"GCP_PROJECT_ID\"], location=os.environ[\"GCP_LOCATION\"]\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001', contents='Why is the sky blue?'\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
