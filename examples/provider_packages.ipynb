{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36183997",
   "metadata": {},
   "source": [
    "# Provider Packages ðŸ“¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3edea794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9bb253",
   "metadata": {},
   "source": [
    "## Anthropic\n",
    "### General hosting via Anthropic\n",
    "Note that it will **by default take the enviroment variable ANTHROPIC_API_KEY** as API key\n",
    "\n",
    "- Python SDK Docs: https://github.com/anthropics/anthropic-sdk-python\n",
    "\n",
    "#### NORMAL CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be232aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01KShvuKMU8of3Z93HXA3NYf',\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"Hello! It's nice to meet you. How are you doing today? Is there anything I can help you with or would you like to chat about?\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 10,\n",
       "  'output_tokens': 34,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import anthropic\n",
    "\n",
    "client = anthropic.Anthropic()\n",
    "message = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n",
    "    ]\n",
    ")\n",
    "message.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a49ed6",
   "metadata": {},
   "source": [
    "#### TOOL USE (FUNCTION CALLING)\n",
    "\n",
    "**Note you can also do multiple tool calls at once:**\n",
    "\n",
    "In this case, Claude will most likely try to use two separate tools, one at a time â€” get_weather and then get_time â€” in order to fully answer the userâ€™s question. However, it will also occasionally output two tool_use blocks at once, particularly if they are not dependent on each other. You would need to execute each tool and return their results in separate tool_result blocks within a single user message.\n",
    "\n",
    "Note that for AnthropicVertex tool calling works exacly the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90f35b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"What's the weather like in San Francisco?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': [{'citations': None,\n",
       "    'text': \"I'll check the current weather in San Francisco for you.\",\n",
       "    'type': 'text'},\n",
       "   {'id': 'toolu_01XAqMECATPXy3iW9RcrkK81',\n",
       "    'input': {'location': 'San Francisco, CA'},\n",
       "    'name': 'get_weather',\n",
       "    'type': 'tool_use'}]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single tool call example\n",
    "\n",
    "messages=[{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco?\"}]\n",
    "tools=[\n",
    "        {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-opus-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    tools=tools,\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "# Append the tool call to the message\n",
    "\n",
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": response.model_dump()['content']\n",
    "})\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2ad2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_012r7NgjKAUvF7ocM2VLzNR6',\n",
       " 'content': [{'citations': None,\n",
       "   'text': \"The current weather in San Francisco is 65 degrees Fahrenheit. It's a comfortable temperature - not too hot and not too cold!\",\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-opus-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 487,\n",
       "  'output_tokens': 32,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': 'standard'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's say we execute the tool call\n",
    "# Import we pass back the tool use id and the content\n",
    "\n",
    "response_message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"tool_result\",\n",
    "                    \"tool_use_id\": \"toolu_01XAqMECATPXy3iW9RcrkK81\", # from the API response\n",
    "                    \"content\": \"65 degrees\" # from running your tool\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "messages.append(response_message)\n",
    "response = client.messages.create(\n",
    "    model=\"claude-opus-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    tools=tools,\n",
    "    messages=messages)\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d688c",
   "metadata": {},
   "source": [
    "### Hosting via VertexAI (Google Cloud)\n",
    "Here it's important to always specify the project ID from your Google Cloud project and the region where you want to model from what region you want to run inferance on.\n",
    "\n",
    "- Check the [Vertex AI Locations](https://cloud.google.com/vertex-ai/docs/general/locations) for more information about the specifc regions.\n",
    "- The Python SDK information: https://docs.anthropic.com/en/api/claude-on-vertex-ai\n",
    "- Tool calling and other functions are the same as for the base Anthropic implementation\n",
    "\n",
    "#### NORMAL CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "459f701e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_vrtx_01StPvFNLWbwjDxrDjNyUrXh',\n",
       " 'content': [{'citations': None,\n",
       "   'text': 'Hey there! Nice to meet you. How are you doing today?',\n",
       "   'type': 'text'}],\n",
       " 'model': 'claude-sonnet-4-20250514',\n",
       " 'role': 'assistant',\n",
       " 'stop_reason': 'end_turn',\n",
       " 'stop_sequence': None,\n",
       " 'type': 'message',\n",
       " 'usage': {'cache_creation_input_tokens': 0,\n",
       "  'cache_read_input_tokens': 0,\n",
       "  'input_tokens': 10,\n",
       "  'output_tokens': 17,\n",
       "  'server_tool_use': None,\n",
       "  'service_tier': None}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from anthropic import AnthropicVertex\n",
    "\n",
    "project_id = os.getenv(\"GCP_PROJECT_ID\")\n",
    "# Where the model is running\n",
    "region = os.getenv(\"GCP_LOCATION\")\n",
    "client = AnthropicVertex(project_id=project_id, region=region)\n",
    "\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4@20250514\",\n",
    "    max_tokens=100,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hey Claude!\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5278b355",
   "metadata": {},
   "source": [
    "## OpenAI\n",
    "### General hosting via OpenAI\n",
    "Note that **it will take by default the enviroment variable OPENAI_API_KEY** as API KEY\n",
    "\n",
    "- [Python SDK Docs](https://platform.openai.com/docs/libraries?language=python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13b0a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'resp_6838a579732481918e0de46b47ce20ce0daf024ae84bc2b2',\n",
       " 'created_at': 1748542841.0,\n",
       " 'error': None,\n",
       " 'incomplete_details': None,\n",
       " 'instructions': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4.1-2025-04-14',\n",
       " 'object': 'response',\n",
       " 'output': [{'id': 'msg_6838a57a362081919667e093cf86f7f70daf024ae84bc2b2',\n",
       "   'content': [{'annotations': [],\n",
       "     'text': 'Under a moonlit sky, a gentle unicorn tiptoed across rainbow clouds, sprinkling sweet dreams over sleeping children below.',\n",
       "     'type': 'output_text'}],\n",
       "   'role': 'assistant',\n",
       "   'status': 'completed',\n",
       "   'type': 'message'}],\n",
       " 'parallel_tool_calls': True,\n",
       " 'temperature': 1.0,\n",
       " 'tool_choice': 'auto',\n",
       " 'tools': [],\n",
       " 'top_p': 1.0,\n",
       " 'background': False,\n",
       " 'max_output_tokens': None,\n",
       " 'previous_response_id': None,\n",
       " 'reasoning': {'effort': None, 'generate_summary': None, 'summary': None},\n",
       " 'service_tier': 'default',\n",
       " 'status': 'completed',\n",
       " 'text': {'format': {'type': 'text'}},\n",
       " 'truncation': 'disabled',\n",
       " 'usage': {'input_tokens': 18,\n",
       "  'input_tokens_details': {'cached_tokens': 0},\n",
       "  'output_tokens': 26,\n",
       "  'output_tokens_details': {'reasoning_tokens': 0},\n",
       "  'total_tokens': 44},\n",
       " 'user': None,\n",
       " 'store': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f765132",
   "metadata": {},
   "source": [
    "#### TOOL USE (FUNCTION CALLING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3047c669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is the weather like in Paris today?'},\n",
       " {'arguments': '{\"location\":\"Paris, France\"}',\n",
       "  'call_id': 'call_wnQhXnJrWW2lXwqkOONxZoxb',\n",
       "  'name': 'get_weather',\n",
       "  'type': 'function_call',\n",
       "  'id': 'fc_6838a57c870c8191b10b55341308b6cb0f1f7e08fa79aafe',\n",
       "  'status': 'completed'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for a given location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"City and country e.g. BogotÃ¡, Colombia\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"location\"\n",
    "        ],\n",
    "        \"additionalProperties\": False # This parameter is not available for both Anthropic and Google\n",
    "    }\n",
    "}]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the weather like in Paris today?\"}\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# Note that we did not assign a role for the tool arguments provided by OpenAI\n",
    "messages.extend(response.model_dump()['output'])\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dd8268b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'msg_6838a58218848191be69fea7d86a7a240f1f7e08fa79aafe',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': 'The weather in Paris today is sunny with a temperature of 20Â°C.',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = {\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": 'call_wnQhXnJrWW2lXwqkOONxZoxb', # from the API response\n",
    "    \"output\": \"The weather in Paris is sunny with a temperature of 20 degrees Celsius.\"\n",
    "}\n",
    "\n",
    "messages.append(response)\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "response.model_dump()['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254c191f",
   "metadata": {},
   "source": [
    "### Hosting via Azure\n",
    "\n",
    "Check the documentation [here](https://learn.microsoft.com/en-gb/azure/ai-services/openai/supported-languages?tabs=dotnet-secure%2Csecure%2Cpython-key%2Ccommand&pivots=programming-language-pythong)\n",
    "\n",
    "Note that not all models are available in every region, most EU models are available in **swedencentral** and US models in **eastus2**\n",
    "Also remember to deploy the model you want to use on https://ai.azure.com/\n",
    "\n",
    "- Azure OpenAI uses the same principles for calling functions as the base OpenAI Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ef3fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "    api_version=\"2025-01-01-preview\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",  # e.g. gpt-35-instant\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do I output all files in a directory using Python?\",\n",
    "        },\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4387c",
   "metadata": {},
   "source": [
    "## Google\n",
    "### General Hosting (via AI Studio)\n",
    "\n",
    "- Check the documentation on GitHub [here](https://github.com/googleapis/python-genai).\n",
    "\n",
    "#### NORMAL CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ccb4e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': [{'content': {'parts': [{'video_metadata': None,\n",
       "      'thought': None,\n",
       "      'inline_data': None,\n",
       "      'code_execution_result': None,\n",
       "      'executable_code': None,\n",
       "      'file_data': None,\n",
       "      'function_call': None,\n",
       "      'function_response': None,\n",
       "      'text': \"The sky appears blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown of why:\\n\\n*   **Sunlight is composed of all colors:** White sunlight is actually a mix of all the colors of the rainbow.\\n\\n*   **Sunlight interacts with the atmosphere:** As sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of light:** This collision causes the sunlight to scatter in different directions. The amount of scattering depends on the wavelength (color) of the light.\\n\\n*   **Rayleigh scattering favors shorter wavelengths:** Rayleigh scattering is much more effective at scattering shorter wavelengths of light, like blue and violet.\\n\\n*   **Why blue instead of violet?** While violet light is scattered even more, the sun emits less violet light, and our eyes are more sensitive to blue light. Also, some violet light is absorbed higher in the atmosphere. As a result, we see a predominantly blue sky.\\n\\n**In simple terms:**\\n\\nImagine throwing different sized balls (colors of light) at a bunch of small obstacles (air molecules). The smaller balls (blue and violet light) will bounce around more easily than the bigger balls (red and orange light). This bouncing around of the blue light is what makes the sky appear blue to us.\\n\\n**Why are sunsets red/orange?**\\n\\nAt sunset and sunrise, the sunlight has to travel through much more of the atmosphere to reach our eyes. Because of this, most of the blue light has already been scattered away by the time the sunlight reaches us directly. This leaves the longer wavelengths (red and orange) to dominate, giving us those beautiful sunset colors.\"}],\n",
       "    'role': 'model'},\n",
       "   'citation_metadata': {'citations': [{'end_index': 377,\n",
       "      'license': None,\n",
       "      'publication_date': None,\n",
       "      'start_index': 243,\n",
       "      'title': None,\n",
       "      'uri': None}]},\n",
       "   'finish_message': None,\n",
       "   'token_count': None,\n",
       "   'finish_reason': <FinishReason.STOP: 'STOP'>,\n",
       "   'url_context_metadata': None,\n",
       "   'avg_logprobs': -0.24277438841004303,\n",
       "   'grounding_metadata': None,\n",
       "   'index': None,\n",
       "   'logprobs_result': None,\n",
       "   'safety_ratings': None}],\n",
       " 'create_time': None,\n",
       " 'response_id': None,\n",
       " 'model_version': 'gemini-2.0-flash-001',\n",
       " 'prompt_feedback': None,\n",
       " 'usage_metadata': {'cache_tokens_details': None,\n",
       "  'cached_content_token_count': None,\n",
       "  'candidates_token_count': 345,\n",
       "  'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>,\n",
       "    'token_count': 345}],\n",
       "  'prompt_token_count': 6,\n",
       "  'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>,\n",
       "    'token_count': 6}],\n",
       "  'thoughts_token_count': None,\n",
       "  'tool_use_prompt_token_count': None,\n",
       "  'tool_use_prompt_tokens_details': None,\n",
       "  'total_token_count': 351,\n",
       "  'traffic_type': None},\n",
       " 'automatic_function_calling_history': [],\n",
       " 'parsed': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001', contents='Why is the sky blue?'\n",
    ")\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76bad6",
   "metadata": {},
   "source": [
    "#### TOOL USE / FUNCTION CALLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62ed112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'candidates': [{'content': {'parts': [{'video_metadata': None,\n",
       "      'thought': None,\n",
       "      'inline_data': None,\n",
       "      'code_execution_result': None,\n",
       "      'executable_code': None,\n",
       "      'file_data': None,\n",
       "      'function_call': {'id': None,\n",
       "       'args': {'location': 'Paris, France'},\n",
       "       'name': 'get_weather'},\n",
       "      'function_response': None,\n",
       "      'text': None}],\n",
       "    'role': 'model'},\n",
       "   'citation_metadata': None,\n",
       "   'finish_message': None,\n",
       "   'token_count': None,\n",
       "   'finish_reason': <FinishReason.STOP: 'STOP'>,\n",
       "   'url_context_metadata': None,\n",
       "   'avg_logprobs': -0.002455611580184528,\n",
       "   'grounding_metadata': None,\n",
       "   'index': None,\n",
       "   'logprobs_result': None,\n",
       "   'safety_ratings': None}],\n",
       " 'create_time': None,\n",
       " 'response_id': None,\n",
       " 'model_version': 'gemini-2.0-flash',\n",
       " 'prompt_feedback': None,\n",
       " 'usage_metadata': {'cache_tokens_details': None,\n",
       "  'cached_content_token_count': None,\n",
       "  'candidates_token_count': 7,\n",
       "  'candidates_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>,\n",
       "    'token_count': 7}],\n",
       "  'prompt_token_count': 34,\n",
       "  'prompt_tokens_details': [{'modality': <MediaModality.TEXT: 'TEXT'>,\n",
       "    'token_count': 34}],\n",
       "  'thoughts_token_count': None,\n",
       "  'tool_use_prompt_token_count': None,\n",
       "  'tool_use_prompt_tokens_details': None,\n",
       "  'total_token_count': 41,\n",
       "  'traffic_type': None},\n",
       " 'automatic_function_calling_history': [],\n",
       " 'parsed': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "tools = [{\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for a given location.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"City and country e.g. BogotÃ¡, Colombia\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\n",
    "            \"location\"\n",
    "        ],\n",
    "        }\n",
    "}]\n",
    "\n",
    "messages =  [\n",
    "    types.Content(\n",
    "        role=\"user\", parts=[types.Part(text=\"What is the weather like in Paris today?\")]\n",
    "    )\n",
    "]\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "tools = types.Tool(function_declarations=tools)\n",
    "config = types.GenerateContentConfig(tools=[tools])\n",
    "\n",
    "\n",
    "# Send request with function declarations\n",
    "response = client.models.generate_content(\n",
    "     model=\"gemini-2.0-flash\",\n",
    "     contents=messages,\n",
    "     config=config,\n",
    ")\n",
    "\n",
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb964cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': {'parts': [{'video_metadata': None,\n",
       "    'thought': None,\n",
       "    'inline_data': None,\n",
       "    'code_execution_result': None,\n",
       "    'executable_code': None,\n",
       "    'file_data': None,\n",
       "    'function_call': None,\n",
       "    'function_response': None,\n",
       "    'text': 'The weather in Paris today is 20 degrees Celsius and sunny.\\n'}],\n",
       "  'role': 'model'},\n",
       " 'citation_metadata': None,\n",
       " 'finish_message': None,\n",
       " 'token_count': None,\n",
       " 'finish_reason': <FinishReason.STOP: 'STOP'>,\n",
       " 'url_context_metadata': None,\n",
       " 'avg_logprobs': -0.0008741534625490506,\n",
       " 'grounding_metadata': None,\n",
       " 'index': None,\n",
       " 'logprobs_result': None,\n",
       " 'safety_ratings': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append(response.candidates[0].content)\n",
    "\n",
    "# Create a function response part\n",
    "function_response_part = types.Part.from_function_response(\n",
    "    name=\"get_weather\",\n",
    "    response={\"result\": \"20 degrees Celsius and sunny\"},\n",
    ")\n",
    "\n",
    "messages.append(types.Content(role=\"user\", parts=[function_response_part]))\n",
    "\n",
    "final_response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=messages,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "final_response.model_dump()['candidates'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33153af",
   "metadata": {},
   "source": [
    "### Hosting via VertexAI\n",
    "We do this using the same package as before but we now set the project id and location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38e08ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text=\"The sky is blue because of a phenomenon called **Rayleigh scattering**. Here's the breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:**  Rayleigh scattering is more effective at scattering shorter wavelengths of light. Blue and violet light have shorter wavelengths than other colors like red, orange, and yellow.\\n\\n*   **Why Blue, Not Violet?** While violet light has an even shorter wavelength than blue and is scattered more, there's less violet light in sunlight to begin with. Also, our eyes are more sensitive to blue light than violet.\\n\\n**In summary:** Blue light is scattered more than other colors by the atmosphere, making the sky appear blue to our eyes.\\n\\n**Think of it like this:** Imagine throwing a bunch of marbles of different sizes at a collection of small obstacles. The smaller marbles (blue light) will bounce off in many directions, while the larger marbles (red light) will be more likely to go straight through.\\n\\n**Why Sunsets are Red:**\\n\\nAt sunrise and sunset, the sunlight has to travel through much more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away by the time the sunlight reaches us. The longer wavelengths like red and orange are less scattered and can pass through the atmosphere more easily, giving the sky those warm sunset colors.\")], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=1463, license=None, publication_date=None, start_index=1315, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.24306822659676536, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)], create_time=datetime.datetime(2025, 5, 29, 18, 21, 7, 593254, tzinfo=TzInfo(UTC)), response_id='k6U4aOaaJJjTxN8Pn_WpsAM', model_version='gemini-2.0-flash-001', prompt_feedback=None, usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=342, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=342)], prompt_token_count=6, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=6)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=348, traffic_type=<TrafficType.ON_DEMAND: 'ON_DEMAND'>), automatic_function_calling_history=[], parsed=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# Only run this block for Vertex AI API\n",
    "client = genai.Client(\n",
    "    vertexai=True, project=os.environ[\"GCP_PROJECT_ID\"], location=os.environ[\"GCP_LOCATION\"]\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001', contents='Why is the sky blue?'\n",
    ")\n",
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
